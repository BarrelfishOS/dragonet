## -*- mode: python; coding: utf-8 -*-

include('netperf_definitions.inc')
include('useful_funs.inc')
AGGREGATOR='summary'
#AGGREGATOR='timeseries'
#DESCRIPTION='UDP Transactions'
DESCRIPTION='FancyEcho scalability'
DEFAULTS={'PLOT': 'lbest'}
TESTNAME='UDP_RR'
#ITERATIONS=3

def real_test_name():
    """retuns the real test name """
    if (USE_TCP) :
        return "tcp_rr"
    else :
        return "udp_rr"


TESTNAME = real_test_name()

RESULT_LOCATION_BASE = '%s_%s' % (RESULT_LOCATION_BASE2, TESTNAME.strip().replace(' ', ''))
# NOTE: The RESULT_LOCATION_BASE  should have absolute path
# NOTE: This location will be created if not present


def getInterruptLines(minfo):
    netdev = minfo["EGRESS_INFO"]["iface"]
    if netdev == None or netdev == 'lo' or netdev == "" :
        return ""
    if not 'INTERRUPTS' in  minfo["EGRESS_INFO"].keys():
        return ""
    ints = minfo["EGRESS_INFO"]['INTERRUPTS']
    if ints == None or ints == 'lo' or ints == "" :
        return ""
    return "-I %s" % (ints)

def dstatCmd(mname, outBase=RESULT_LOCATION_BASE, outfname='dstat_out.dstat',
            outjson='dstat_out.json',
            netdev='lo', cpus='3,5',
            runtime=TOTAL_LENGTH,
            interrupts=""
            ):

    if outfname == None or outfname == "" or outfname == False :
        outfname = '/dev/null'
    else :
        outfilename = ('%s_%s/%s' % (RESULT_LOCATION_BASE, mname, outfname))
    outfname = '/dev/null'

    outjsonname = ('%s_%s/%s' % (RESULT_LOCATION_BASE, mname, outjson))
    cmd = '../dstat/dstat --nocolor -J %s -ciny -C%s -N %s %s 1 %d > %s ; cat %s' % (
                   outjsonname, cpus, netdev, interrupts, runtime, outfilename, outjsonname)
    return cmd



#def ethtoolCmd(mname, outBase=RESULT_LOCATION_BASE, netdev, isEnd=False):
#
#    extension="start"
#    if isEnd:
#        extension="end"
#    outfilename = ('%s_%s/ethtoolout.%s' % (RESULT_LOCATION_BASE, mname, extension))
#    cmd="ethtool -S %s > %s " % (netdev, outfilename)
#    return cmd


TOOLS_LOCATION1 = '${HOME}/dragonet/benchmarking/netperf-wrapper/'
TOOLS_LOCATION2 = '${HOME}/git/dragonet/benchmarking/netperf-wrapper/'

def toCoreList(clist):
    ret = ""
    for c in clist:
        if ret == "" :
            ret = "%d" % (c)
        else :
            ret = "%s,%d" % (ret, c)
    return ret

def toCoreListDstat(clist):
    ret = "%d-%d" % (min(clist), max(clist))
    return ret

    port_list_for_clients = expand_client_list(server_names, port_list)

def repeat_list_elem_n_times(elemList, n):
    nlist = []
    for e in elemList:
        for i in range(0, n):
            nlist.append(e)
    return nlist


def expand_client_list(sn, cn):
    cllist = []
    for s in sn:
        for c in cn:
            cllist.append(c)
    return cllist


server_names=[SERVERS[0] for i in range(0, SERVERS_INSTANCES)]
client_names=expand_client_list(server_names, CLIENTS)
server_if = SERVERS_IF
client_if = CLIENTS_IF
echo_server_name = ECHO_SERVER
echo_server_cmds = SRV_CMDS[echo_server_name]
psize = PKT_SIZE

def chunks(l, n):
    """ Yield successive n-sized chunks from l.  """
    for i in xrange(0, len(l), n):
        yield l[i:i+n]

# generates cores to use list while avoiding assigning same core to two
# instances on same machine.
# Essentially it allows having same client multiple times in list of clients
def gen_core_list(mlist, cores_to_alloc, cores_per_machine, starting_core=2):
    cores_to_use = []
    for i in range(0,len(mlist)):
        m = mlist[i]
        existing_duplicates = [x for x in mlist[0:i] if x == m]
        init_core = starting_core + (len(existing_duplicates) * cores_to_alloc)
        # rounding the core id's with number of cores available
        core_use_order = map(
                                (lambda x: x % int(cores_per_machine[m])),
                                range(init_core, (init_core + cores_to_alloc))
                            )
        cores_to_use.append(core_use_order)
        print "Cores used by machine %s: %s" % (m, core_use_order)
    return cores_to_use

client_core_list = gen_core_list(client_names, CLIENT_CORES, CLIENTS_CORECOUNT, starting_core=0)
server_core_list = gen_core_list(server_names, SERVER_CORES, SERVERS_CORECOUNT, starting_core=SERVER_CORESHIFT)

psize = PKT_SIZE
brustsize = BRUST_SIZE
server_onload = SERVER_ONLOAD_CMDLINE
dstat_ignore_initial_x_vals = 4

# FIXME: Change this
custom_header = "pkt=%d, brust=%d srv=%s, onload=%s" % (psize,
            brustsize,
            echo_server_name,
            server_onload,
            )


def get_proto_specific_server_ports():
    """retuns values for to be used for ports at server end """
    port_list = range(SERVER_INITIAL_PORT, (SERVER_INITIAL_PORT + (len(server_names))))
    port_list_empty = [0 for x in port_list]
    port_list_for_clients = repeat_list_elem_n_times(port_list, len(CLIENTS))

    print "port_list_for_clients: %s" % (port_list_for_clients)
    if (USE_TCP) :
        return (port_list_for_clients, port_list,       port_list_empty, "")
    else:
        return (port_list_for_clients, port_list_empty, port_list,       " --udp ")

MEMCACHED_PORT, MEMCACHED_PORT_TCP, MEMCACHED_PORT_UDP, USING_UDP = get_proto_specific_server_ports()



def get_init_cmd_server(id) :
    """Returns special init command when it is first server and there is special init command present"""
    if not id == 0:
        return echo_server_cmds['init_cmd']
    if "init_cmd_special" in echo_server_cmds.keys() :
        return echo_server_cmds['init_cmd_special']
    return echo_server_cmds['init_cmd']


def create_server(id):
    srv = ('server-%d' % (id), {
     'deployment_host': server_names[id],
     'result_location': '%s_server%d' % (RESULT_LOCATION_BASE, id),
     'tools_location': TOOLS_LOCATION1,
     'is_server': True,
     'TOOLS': o([

       ( 'echoServer%d' % (id),
       {
           'command': 'sudo taskset -c %s %s %s ' % (
                toCoreList(server_core_list[id]), server_onload,
                echo_server_cmds['exec_cmd'],
                ),

           'runner': 'process',
           'units': 'Gbits/s',
           'wait_for': False,
           'is_catastrophic': False,
           'init_cmd': get_init_cmd_server(id), # echo_server_cmds['init_cmd'],
           'kill_cmd': echo_server_cmds['kill_cmd'],
           'out_cmd': echo_server_cmds['out_cmd'],
       }),

       ('dstat',
       {
           'command': dstatCmd (mname = 'server%d' % (id),
               cpus=toCoreList(server_core_list[id]), netdev=server_if[server_names[id]],
               interrupts=getInterruptLines(MINFO_SERVER[server_names[id]])),
           'runner': 'dstat_json',
           'wait_for': True,
           'delay': DELAY,
           'is_catastrophic': True,
           'init_cmd': [],
           'out_cmd': [],
           'kill_cmd': [],
       }),


#       ('ethtool',
#       {
#           'command': dstatCmd (mname = 'server%d' % (id),
#               cpus=toCoreList(server_core_list[id]), netdev=server_if[server_names[id]],
#               interrupts=getInterruptLines(MINFO_SERVER[server_names[id]])),
#           'runner': 'ethtool_json',
#           'wait_for': True,
#           'is_catastrophic': True,
#           'init_cmd': [],
#           'out_cmd': [],
#           'kill_cmd': [],
#       }),

       ])}
    )
    return srv

def create_server_list(server_names, startid=SPECIAL_SERVERS_COUNT):
    slist = []
    if startid >= len(server_names):
        return slist
    for i in range(startid, len(server_names)):
       slist.append(create_server(i))
    return slist

def create_special_client(id):
    client_core_list_SP = client_core_list[id][0:1]
    # FIXME: make sure that id is smaller than client_names
    cl = ('clieSP%d' % (id),
         {
          'deployment_host': client_names[id],
          'result_location': '%s_clieSP%d' % (RESULT_LOCATION_BASE, id),
          'tools_location': TOOLS_LOCATION1,
          'is_server': False,
          'TOOLS': o([
            ( 'netperSP%d' % (id),
            {
                'command': 'taskset -c %s %s %s -P 0 -H %s -t %s -l %d -- -r %d -b %d -k all' % (
                    toCoreList(client_core_list_SP), NETPERF_CMD,  echo_server_cmds['client_extra_opts'],
                    TARGET, TESTNAME, TOTAL_LENGTH,
                    psize, brustsize),
                'runner': 'netperf_sumary',
                'units': 'Gbits/s',
                'wait_for': True,
                'delay': DELAY,
                'is_catastrophic': False,
                'init_cmd': [],
                'out_cmd': [],
                'kill_cmd': ["sudo killall netperf || true"],
            }),

            ('dstat',
            {
                'command': dstatCmd (mname = 'clieSP%d' % (id),
                    cpus=toCoreList(client_core_list_SP), netdev=client_if[client_names[id]]),
                'runner': 'dstat_json',
                'wait_for': True,
                'delay': DELAY,
                'is_catastrophic': True,
                'init_cmd': [],
                'out_cmd': [],
                'kill_cmd': [],
            }),


            ]),
          })
    return cl


def create_client(id):
    # FIXME: make sure that id is smaller than client_names
    cl = ('client%d' % (id),
         {
          'deployment_host': client_names[id],
          'result_location': '%s_client%d' % (RESULT_LOCATION_BASE, id),
          'tools_location': TOOLS_LOCATION1,
          'is_server': False,
          'TOOLS': o([
            ( 'netperf%d' % (id),
            {
                'command': 'taskset -c %s %s %s -P 0 -H %s -t %s -l %d -- -r %d -b %d -P ,%d -k all' % (
                    toCoreList(client_core_list[id]), NETPERF_CMD,  echo_server_cmds['client_extra_opts'],
                    TARGET, TESTNAME, TOTAL_LENGTH,
                    psize, brustsize, MEMCACHED_PORT[id]
                    ),
                'runner': 'netperf_sumary',
                'units': 'Gbits/s',
                'wait_for': True,
                'delay': DELAY,
                'is_catastrophic': False,
                'init_cmd': [],
                'out_cmd': [],
                'kill_cmd': ["sudo killall netperf || true"],
            }),

#            ('dstat',
#            {
#                'command': dstatCmd (mname = 'client%d' % (id),
#                    cpus=toCoreList(client_core_list[id]), netdev=client_if[client_names[id]]),
#                'runner': 'dstat_json',
#                'wait_for': True,
#                'delay': DELAY,
#                'is_catastrophic': True,
#                'init_cmd': [],
#                'out_cmd': [],
#                'kill_cmd': [],
#            }),
#

            ]),
          })
    return cl

def create_client_list(client_names, startid=SPECIAL_CLIENTS_COUNT):
    clist = []
    if startid >= len(client_names):
        return clist
    for i in range(startid, len(client_names)):
       clist.append(create_client(i))
    return clist

def create_special_client_list(client_names, spcount=SPECIAL_CLIENTS_COUNT):
    clist = []
    if spcount > len(client_names):
        spcount = len(client_names)
    for i in range(0, spcount):
       clist.append(create_special_client(i))
    return clist

def create_special_client_attr(id, mname, attr, label, func):
    if label == None or label == "" :
        label = attr
    label = ("SP_%s_%d_%s" % (label, id, mname))
    return result_attr_wrapper(attr, c="netperSP%d" % (id), l=label, func=func)


def create_special_client_attr_list(client_names,  attr, label=None,
                    func=None, spcount=SPECIAL_CLIENTS_COUNT):
    clist = []
    if spcount > len(client_names):
        spcount = len(client_names)
    for i in range(0, spcount):
       clist.append(create_special_client_attr(i, client_names[i], attr, label, func))
    return clist


def create_client_attr(id, mname, attr, label, func):
    if label == None or label == "" :
        label = attr
    label = ("%s_%d_%s" % (label, id, mname))
    return result_attr_wrapper(attr, c="netperf%d" % (id), l=label, func=func)


def create_client_attr_list(client_names,  attr, label=None, func=None,
        startid=SPECIAL_CLIENTS_COUNT):
    clist = []
    if startid >= len(client_names):
        return clist
    for i in range(startid, len(client_names)):
       clist.append(create_client_attr(i, client_names[i], attr, label, func))
    return clist


DATA_SETS = o(
        []
        + create_server_list(server_names)
        + create_special_client_list(client_names)
        + create_client_list(client_names)
        )



def valid_tps(vals) :
    if vals == None or vals == []:
        return 0
    if min(vals) == 0 :
        return 0
    else:
        return sum(vals)

def add_bw(vals) :
    bw = []
    if vals == None or vals == []:
        return 0
    for v in vals:
        if v[-3] == 'M':
            bw.append(float(v[:-3]))
    return sum(bw)

def client_core_list_wrapper():
    if len(client_core_list) > SPECIAL_CLIENTS_COUNT:
        return client_core_list[SPECIAL_CLIENTS_COUNT]
    return []



ATTRIBUTES = o([
    ( 'attrs',
        { 'attrlist' : [
                    meta_attr_wrapper('ECHO_SERVER', l="Server"),
                    meta_attr_wrapper('HWQUEUES'),
                    meta_attr_wrapper('SERVERS_INSTANCES'),
#                    meta_attr_wrapper('SERVERS', agg=len),
                    meta_attr_wrapper('SERVER_CORES'),
                    meta_attr_wrapper('CLIENTS', agg=(lambda x: len(x) - SPECIAL_CLIENTS_COUNT)),
                    meta_attr_wrapper('TCONCURRENCY'),
                    meta_attr_wrapper('CONCURRENCY'),
#                    result_attr_wrapper("cpu", c="server", l="S CPU", func=get_dstat_attr_cpu, agg=myavg),
                    #result_attr_wrapper("cpu", c="client", l="C CPU", func=get_dstat_attr_cpu, agg=myavg),
                    result_attr_wrapper('TRANSACTION_RATE', c="netperf", l="total TPS", agg=valid_tps),
                    result_attr_wrapper('THROUGHPUT', c="netperf", l="Net_rate", agg=sum),

                    result_attr_wrapper('TRANSACTION_RATE', c="netperf", l="avg TPS", agg=myavg),
                    result_attr_wrapper('MIN_LATENCY', c="netperf", l="get_min", agg=myavg),

                    result_attr_wrapper('MIN_LATENCY', c="netperf", agg=myavg),
                    result_attr_wrapper('RT_LATENCY', c="netperf", agg=myavg),
                    result_attr_wrapper('P50_LATENCY', c="netperf", agg=myavg),
                    result_attr_wrapper('P90_LATENCY', c="netperf", agg=myavg),
                    result_attr_wrapper('P99_LATENCY', c="netperf", agg=myavg),
                    result_attr_wrapper('MAX_LATENCY', c="netperf", agg=myavg),
                    ]
                    + create_special_client_attr_list(client_names, attr= 'RT_LATENCY')
                    + create_special_client_attr_list(client_names, attr= 'TRANSACTION_RATE')

                    + [
                    meta_attr_wrapper('USE_TCP'),
                    #meta_attr_wrapper('SERVER_ONLOAD_CMDLINE', l="Onload"),
                    #meta_attr_wrapper('TARGET'),
                    #result_attr_wrapper('threads count', c="memaslap%d"% (SPECIAL_CLIENTS_COUNT)),
                    #result_attr_wrapper('concurrency', c="memaslap%d" % (SPECIAL_CLIENTS_COUNT)),
                    #result_attr_wrapper('windows size', c="memaslap%d" % (
                    #        SPECIAL_CLIENTS_COUNT), func=get_result_str, agg=find_uniq),

#                   {
#                    'data': get_interrupts,
#                    'args' : {
#                            'mname': 'server-0',
#                            'takeAvg': True},
#                    'label': 'NIC Interrupts'
#                   },

                    meta_attr_wrapper('TITLE'),
                ]
        }
    )
])



PLOTS = o([
    ('bbox',
     {
      #'description': 'Server: %s, Target: %s, TCP: %s' % (ECHO_SERVER, TARGET, USE_TCP),
      'description': 'TPS, Server: %s, Target: %s %s' % (
            ECHO_SERVER, SERVERS_DRV[SERVERS[0]], TARGET),
      'axis_labels': ["Maximum TPS"],
      'xaxis_label': ["HW queues, Srv Ports, Threads/Port, (simulated clients)"],
      'series': [
                   #meta_attr_wrapper('ECHO_SERVER'),
                   #meta_attr_wrapper('SERVER_ONLOAD_CMDLINE'),
                   #meta_attr_wrapper('TARGET'),
                   #netperf_attr_wrapper ('REQUEST_SIZE'),
                   #netperf_attr_wrapper ('BURST_SIZE'),
                   result_attr_wrapper('TRANSACTION_RATE', l="total TPS"),
                   result_attr_wrapper('THROUGHPUT', l="Net_rate"),
                   #netperf_attr_wrapper ('MIN_LATENCY'),
                ],
      'type': 'box2',}),

    ('bboxNet',
     {
      #'description': 'Server: %s, Target: %s, TCP: %s' % (ECHO_SERVER, TARGET, USE_TCP),
      'description': 'Bandwidth, Server: %s, Target: %s %s' % (
            ECHO_SERVER, SERVERS_DRV[SERVERS[0]], TARGET),
      'axis_labels': ["Bandwidth (Gbps)"],
      'xaxis_label': ["HW queues, Srv Ports, Threads/Port, (simulated clients)"],
      'series': [
                   #meta_attr_wrapper('ECHO_SERVER'),
                   #meta_attr_wrapper('SERVER_ONLOAD_CMDLINE'),
                   #meta_attr_wrapper('TARGET'),
                   #netperf_attr_wrapper ('REQUEST_SIZE'),
                   #netperf_attr_wrapper ('BURST_SIZE'),
                   result_attr_wrapper('THROUGHPUT', l="Net_rate"),
                   #netperf_attr_wrapper ('MIN_LATENCY'),
                ],
      'type': 'box2',}),



    ])

#########################################################

