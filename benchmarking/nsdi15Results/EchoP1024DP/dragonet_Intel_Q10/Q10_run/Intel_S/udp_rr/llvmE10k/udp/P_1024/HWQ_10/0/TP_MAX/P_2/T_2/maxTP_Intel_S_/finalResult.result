./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 2 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.96 udp_rr --packet 1024 --concurrency 16 -t llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16 -o ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_/ -L ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_//llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16.log
generating data for machine burrata
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-19:00:48:45:Setting up machines

2014-09-19:00:48:47: Start run

2014-09-19:00:48:47: Starting server applications

2014-09-19:00:48:47: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-19:00:48:47: Starting client applications


2014-09-19:00:48:47: Benchmark running, for threads which are marked for waiting

2014-09-19:00:48:57: Benchmark done (runtime = 9.745021 secs), killing other threads

2014-09-19:00:48:57: Waiting for kill cleanup

2014-09-19:00:48:57: Processing results

2014-09-19:00:48:57: cleaning up server applications


2014-09-19:00:48:57: Done with collecting data


generating filename with title llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
using ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_/udp_rr-2014-09-19T004844.751842.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_16.json.gz as dump file
Test data is in [../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_/udp_rr-2014-09-19T004844.751842.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_16.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
CORES: 2: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
UDP Ports: 1: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
Threads/Port: 2: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
TARGET: 10.113.4.96: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
Server: noServer: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
CLIENTS: 4: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
TCONCURRENCY: 64: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
CONCURRENCY: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
total TPS: [660252.163]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
vtotal TPS: [660252.163]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
Net_rate: [5.41]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
avg TPS: [165063.04075]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
MIN TPS: [149848.805]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
get_min: [57.5]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
MIN_LATENCY: [57.5]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
RT_LATENCY: [103.64125]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
P50_LATENCY: [102.5]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
P90_LATENCY: [115.5]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
P99_LATENCY: [128.5]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
MAX_LATENCY: [352.0]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
USE_TCP: False: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
TITLE: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:2, UDP Ports:1, Threads/Port:2, TARGET:10.113.4.96, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(2, 10, 2, 1, 2, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURRENNo output formatter selected.
Test data is in ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_/udp_rr-2014-09-19T004844.751842.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_16.json.gz (use with -i to format).
  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |         2  |         1  |         2  | 10.113.4.  |  noServer  |         4  |        64  |        16  | [660252.1  | [660252.1  |    [5.41]  | [165063.0  | [149848.8  |    [57.5]  |    [57.5]  | [103.6412  |   [102.5]  |   [115.5]  |   [128.5]  |   [352.0]  |     False  |llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 2 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.96 udp_rr --packet 1024 --concurrency 32 -t llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32 -o ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_/ -L ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_//llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32.log
generating data for machine burrata
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-19:00:49:03:Setting up machines

2014-09-19:00:49:06: Start run

2014-09-19:00:49:06: Starting server applications

2014-09-19:00:49:06: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-19:00:49:06: Starting client applications


2014-09-19:00:49:06: Benchmark running, for threads which are marked for waiting

2014-09-19:00:49:15: Benchmark done (runtime = 9.745070 secs), killing other threads

2014-09-19:00:49:15: Waiting for kill cleanup

2014-09-19:00:49:15: Processing results

2014-09-19:00:49:15: cleaning up server applications


2014-09-19:00:49:15: Done with collecting data


generating filename with title llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
using ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_/udp_rr-2014-09-19T004902.860146.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_32.json.gz as dump file
Test data is in [../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_/udp_rr-2014-09-19T004902.860146.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_32.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
CORES: 2: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
UDP Ports: 1: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
Threads/Port: 2: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
TARGET: 10.113.4.96: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
Server: noServer: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
CLIENTS: 4: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
TCONCURRENCY: 128: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
CONCURRENCY: 32: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
total TPS: [701180.638]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
vtotal TPS: [701180.638]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
Net_rate: [5.74]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
avg TPS: [175295.1595]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
MIN TPS: [154259.156]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
get_min: [51.0]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
MIN_LATENCY: [51.0]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
RT_LATENCY: [189.3775]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
P50_LATENCY: [188.25]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
P90_LATENCY: [202.25]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
P99_LATENCY: [209.5]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
MAX_LATENCY: [451.0]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
USE_TCP: False: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
TITLE: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:2, UDP Ports:1, Threads/Port:2, TARGET:10.113.4.96, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(2, 10, 2, 1, 2, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURRENo output formatter selected.
Test data is in ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_/udp_rr-2014-09-19T004902.860146.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_32.json.gz (use with -i to format).
N  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |         2  |         1  |         2  | 10.113.4.  |  noServer  |         4  |       128  |        32  | [701180.6  | [701180.6  |    [5.74]  | [175295.1  | [154259.1  |    [51.0]  |    [51.0]  | [189.3775  |  [188.25]  |  [202.25]  |   [209.5]  |   [451.0]  |     False  |llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 2 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.96 udp_rr --packet 1024 --concurrency 64 -t llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64 -o ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_/ -L ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_//llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64.log
generating data for machine burrata
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-19:00:49:21:Setting up machines

2014-09-19:00:49:24: Start run

2014-09-19:00:49:24: Starting server applications

2014-09-19:00:49:24: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-19:00:49:24: Starting client applications


2014-09-19:00:49:24: Benchmark running, for threads which are marked for waiting

2014-09-19:00:49:33: Benchmark done (runtime = 9.726492 secs), killing other threads

2014-09-19:00:49:33: Waiting for kill cleanup

2014-09-19:00:49:33: Processing results

2014-09-19:00:49:33: cleaning up server applications


2014-09-19:00:49:33: Done with collecting data


generating filename with title llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
using ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_/udp_rr-2014-09-19T004920.962933.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_64.json.gz as dump file
Test data is in [../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_/udp_rr-2014-09-19T004920.962933.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_64.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
CORES: 2: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
UDP Ports: 1: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
Threads/Port: 2: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
TARGET: 10.113.4.96: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
Server: noServer: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
CLIENTS: 4: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
TCONCURRENCY: 256: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
CONCURRENCY: 64: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
total TPS: [737601.866]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
vtotal TPS: [737601.866]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
Net_rate: [6.04]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
avg TPS: [184400.4665]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
MIN TPS: [157237.073]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
get_min: [56.75]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
MIN_LATENCY: [56.75]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
RT_LATENCY: [355.4855]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
P50_LATENCY: [354.0]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
P90_LATENCY: [372.75]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
P99_LATENCY: [382.0]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
MAX_LATENCY: [617.75]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
USE_TCP: False: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
TITLE: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:2, UDP Ports:1, Threads/Port:2, TARGET:10.113.4.96, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(2, 10, 2, 1, 2, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURNo output formatter selected.
Test data is in ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_/udp_rr-2014-09-19T004920.962933.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_64.json.gz (use with -i to format).
REN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |         2  |         1  |         2  | 10.113.4.  |  noServer  |         4  |       256  |        64  | [737601.8  | [737601.8  |    [6.04]  | [184400.4  | [157237.0  |   [56.75]  |   [56.75]  | [355.4855  |   [354.0]  |  [372.75]  |   [382.0]  |  [617.75]  |     False  |llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 2 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.96 udp_rr --packet 1024 --concurrency 128 -t llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128 -o ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_/ -L ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_//llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128.log
generating data for machine burrata
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-19:00:49:39:Setting up machines

2014-09-19:00:49:42: Start run

2014-09-19:00:49:42: Starting server applications

2014-09-19:00:49:42: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-19:00:49:42: Starting client applications


2014-09-19:00:49:42: Benchmark running, for threads which are marked for waiting

2014-09-19:00:49:51: Benchmark done (runtime = 9.745066 secs), killing other threads

2014-09-19:00:49:51: Waiting for kill cleanup

2014-09-19:00:49:51: Processing results

2014-09-19:00:49:51: cleaning up server applications


2014-09-19:00:49:51: Done with collecting data


generating filename with title llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
using ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_/udp_rr-2014-09-19T004939.008445.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_128.json.gz as dump file
Test data is in [../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_/udp_rr-2014-09-19T004939.008445.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_128.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
CORES: 2: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
UDP Ports: 1: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
Threads/Port: 2: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
TARGET: 10.113.4.96: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
Server: noServer: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
CLIENTS: 4: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
TCONCURRENCY: 512: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
CONCURRENCY: 128: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
total TPS: [726010.4140000001]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
vtotal TPS: [726010.4140000001]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
Net_rate: [5.96]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
avg TPS: [181502.60350000003]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
MIN TPS: [157306.378]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
get_min: [66.0]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
MIN_LATENCY: [66.0]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
RT_LATENCY: [715.79]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
P50_LATENCY: [706.5]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
P90_LATENCY: [750.75]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
P99_LATENCY: [763.5]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
MAX_LATENCY: [951.0]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
USE_TCP: False: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
TITLE: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:2, UDP Ports:1, Threads/Port:2, TARGET:10.113.4.96, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(2, 10, 2, 1, 2, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |  No output formatter selected.
Test data is in ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_Intel_S_/udp_rr-2014-09-19T004939.008445.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_128.json.gz (use with -i to format).
  Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |         2  |         1  |         2  | 10.113.4.  |  noServer  |         4  |       512  |       128  | [726010.4  | [726010.4  |    [5.96]  | [181502.6  | [157306.3  |    [66.0]  |    [66.0]  |  [715.79]  |   [706.5]  |  [750.75]  |   [763.5]  |   [951.0]  |     False  |llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_128  |
