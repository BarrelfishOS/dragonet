./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 16 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.96 udp_rr --packet 1024 --concurrency 16 -t llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16 -o ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/ -L ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_//llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16.log
generating data for machine burrata
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-19:01:12:18:Setting up machines

2014-09-19:01:12:28: Start run

2014-09-19:01:12:28: Starting server applications

2014-09-19:01:12:28: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-19:01:12:28: Starting client applications


2014-09-19:01:12:28: Benchmark running, for threads which are marked for waiting

2014-09-19:01:12:38: Benchmark done (runtime = 10.045916 secs), killing other threads

2014-09-19:01:12:38: Waiting for kill cleanup

2014-09-19:01:12:38: Processing results

2014-09-19:01:12:38: cleaning up server applications


2014-09-19:01:12:38: Done with collecting data


generating filename with title llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
using ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/udp_rr-2014-09-19T011217.788203.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_16.json.gz as dump file
Test data is in [../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/udp_rr-2014-09-19T011217.788203.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_16.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
CORES: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
UDP Ports: 1: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
Threads/Port: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
TARGET: 10.113.4.96: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
Server: noServer: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
CLIENTS: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
TCONCURRENCY: 256: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
CONCURRENCY: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
total TPS: [990192.2660000001]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
vtotal TPS: [990192.2660000001]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
Net_rate: [8.110000000000001]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
avg TPS: [61887.016625000004]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
MIN TPS: [50088.068]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
get_min: [58.8125]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
MIN_LATENCY: [58.8125]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
RT_LATENCY: [278.47918749999997]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
P50_LATENCY: [198.5625]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
P90_LATENCY: [481.5]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
P99_LATENCY: [1426.0]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
MAX_LATENCY: [10765.25]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
USE_TCP: False: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
TITLE: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16: No output formatter selected.
Test data is in ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/udp_rr-2014-09-19T011217.788203.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_16.json.gz (use with -i to format).
llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:16, UDP Ports:1, Threads/Port:16, TARGET:10.113.4.96, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(16, 10, 16, 1, 16, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        16  |         1  |        16  | 10.113.4.  |  noServer  |        16  |       256  |        16  | [990192.2  | [990192.2  | [8.110000  | [61887.01  | [50088.06  | [58.8125]  | [58.8125]  | [278.4791  | [198.5625  |   [481.5]  |  [1426.0]  | [10765.25  |     False  |llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 16 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.96 udp_rr --packet 1024 --concurrency 32 -t llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32 -o ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/ -L ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_//llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32.log
generating data for machine burrata
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-19:01:12:43:Setting up machines

2014-09-19:01:12:53: Start run

2014-09-19:01:12:53: Starting server applications

2014-09-19:01:12:53: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-19:01:12:53: Starting client applications


2014-09-19:01:12:53: Benchmark running, for threads which are marked for waiting

2014-09-19:01:13:03: Benchmark done (runtime = 9.989357 secs), killing other threads

2014-09-19:01:13:03: Waiting for kill cleanup

2014-09-19:01:13:03: Processing results

2014-09-19:01:13:03: cleaning up server applications


2014-09-19:01:13:03: Done with collecting data


generating filename with title llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
using ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/udp_rr-2014-09-19T011243.310232.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_32.json.gz as dump file
Test data is in [../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/udp_rr-2014-09-19T011243.310232.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_32.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
CORES: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
UDP Ports: 1: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
Threads/Port: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
TARGET: 10.113.4.96: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
Server: noServer: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
CLIENTS: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
TCONCURRENCY: 512: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
CONCURRENCY: 32: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
total TPS: [1014303.2650000001]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
vtotal TPS: [1014303.2650000001]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
Net_rate: [8.299999999999999]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
avg TPS: [63393.95406250001]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
MIN TPS: [55743.694]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
get_min: [63.375]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
MIN_LATENCY: [63.375]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
RT_LATENCY: [523.03575]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
P50_LATENCY: [454.3125]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
P90_LATENCY: [861.125]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
P99_LATENCY: [1334.3125]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
MAX_LATENCY: [7967.0]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
USE_TCP: False: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
TITLE: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32: llvmE10kNo output formatter selected.
Test data is in ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/udp_rr-2014-09-19T011243.310232.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_32.json.gz (use with -i to format).
,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:16, UDP Ports:1, Threads/Port:16, TARGET:10.113.4.96, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(16, 10, 16, 1, 16, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        16  |         1  |        16  | 10.113.4.  |  noServer  |        16  |       512  |        32  | [1014303.  | [1014303.  | [8.299999  | [63393.95  | [55743.69  |  [63.375]  |  [63.375]  | [523.0357  | [454.3125  | [861.125]  | [1334.312  |  [7967.0]  |     False  |llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 16 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.96 udp_rr --packet 1024 --concurrency 64 -t llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64 -o ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/ -L ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_//llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64.log
generating data for machine burrata
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-19:01:13:09:Setting up machines

2014-09-19:01:13:18: Start run

2014-09-19:01:13:18: Starting server applications

2014-09-19:01:13:18: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-19:01:13:18: Starting client applications


2014-09-19:01:13:18: Benchmark running, for threads which are marked for waiting

2014-09-19:01:13:29: Benchmark done (runtime = 10.031088 secs), killing other threads

2014-09-19:01:13:29: Waiting for kill cleanup

2014-09-19:01:13:29: Processing results

2014-09-19:01:13:29: cleaning up server applications


2014-09-19:01:13:29: Done with collecting data


generating filename with title llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
using ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/udp_rr-2014-09-19T011308.782274.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_64.json.gz as dump file
Test data is in [../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/udp_rr-2014-09-19T011308.782274.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_64.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
CORES: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
UDP Ports: 1: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
Threads/Port: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
TARGET: 10.113.4.96: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
Server: noServer: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
CLIENTS: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
TCONCURRENCY: 1024: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
CONCURRENCY: 64: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
total TPS: [1129599.9270000001]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
vtotal TPS: [1129599.9270000001]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
Net_rate: [9.239999999999998]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
avg TPS: [70599.99543750001]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
MIN TPS: [60641.826]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
get_min: [101.6875]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
MIN_LATENCY: [101.6875]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
RT_LATENCY: [929.3306875]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
P50_LATENCY: [914.4375]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
P90_LATENCY: [1193.8125]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
P99_LATENCY: [1498.75]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
MAX_LATENCY: [5259.5625]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
USE_TCP: False: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
TITLE: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_6No output formatter selected.
Test data is in ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/udp_rr-2014-09-19T011308.782274.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_64.json.gz (use with -i to format).
4: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:16, UDP Ports:1, Threads/Port:16, TARGET:10.113.4.96, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(16, 10, 16, 1, 16, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        16  |         1  |        16  | 10.113.4.  |  noServer  |        16  |      1024  |        64  | [1129599.  | [1129599.  | [9.239999  | [70599.99  | [60641.82  | [101.6875  | [101.6875  | [929.3306  | [914.4375  | [1193.812  | [1498.75]  | [5259.562  |     False  |llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 16 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.96 udp_rr --packet 1024 --concurrency 128 -t llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128 -o ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/ -L ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_//llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128.log
generating data for machine burrata
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-19:01:13:34:Setting up machines

2014-09-19:01:13:44: Start run

2014-09-19:01:13:44: Starting server applications

2014-09-19:01:13:44: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-19:01:13:44: Starting client applications


2014-09-19:01:13:44: Benchmark running, for threads which are marked for waiting

2014-09-19:01:13:54: Benchmark done (runtime = 10.041164 secs), killing other threads

2014-09-19:01:13:54: Waiting for kill cleanup

2014-09-19:01:13:54: Processing results

2014-09-19:01:13:54: cleaning up server applications


2014-09-19:01:13:54: Done with collecting data


generating filename with title llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
using ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/udp_rr-2014-09-19T011334.166666.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_128.json.gz as dump file
Test data is in [../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/udp_rr-2014-09-19T011334.166666.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_128.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
CORES: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
UDP Ports: 1: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
Threads/Port: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
TARGET: 10.113.4.96: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
Server: noServer: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
CLIENTS: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
TCONCURRENCY: 2048: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
CONCURRENCY: 128: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
total TPS: [1148696.369]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
vtotal TPS: [1148696.369]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
Net_rate: [9.42]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
avg TPS: [71793.5230625]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
MIN TPS: [54424.274]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
get_min: [107.1875]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
MIN_LATENCY: [107.1875]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
RT_LATENCY: [1850.5626249999998]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
P50_LATENCY: [1848.4375]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
P90_LATENCY: [2140.75]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
P99_LATENCY: [2413.5]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
MAX_LATENCY: [6383.125]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
USE_TCP: False: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
TITLE: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_12No output formatter selected.
Test data is in ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/udp_rr-2014-09-19T011334.166666.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_128.json.gz (use with -i to format).
8: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:16, UDP Ports:1, Threads/Port:16, TARGET:10.113.4.96, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(16, 10, 16, 1, 16, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        16  |         1  |        16  | 10.113.4.  |  noServer  |        16  |      2048  |       128  | [1148696.  | [1148696.  |    [9.42]  | [71793.52  | [54424.27  | [107.1875  | [107.1875  | [1850.562  | [1848.437  | [2140.75]  |  [2413.5]  | [6383.125  |     False  |llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 16 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.96 udp_rr --packet 1024 --concurrency 256 -t llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256 -o ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/ -L ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_//llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256.log
generating data for machine burrata
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-19:01:13:59:Setting up machines

2014-09-19:01:14:09: Start run

2014-09-19:01:14:09: Starting server applications

2014-09-19:01:14:09: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-19:01:14:09: Starting client applications


2014-09-19:01:14:09: Benchmark running, for threads which are marked for waiting

2014-09-19:01:14:19: Benchmark done (runtime = 10.013115 secs), killing other threads

2014-09-19:01:14:19: Waiting for kill cleanup

2014-09-19:01:14:19: Processing results

2014-09-19:01:14:19: cleaning up server applications


2014-09-19:01:14:19: Done with collecting data


generating filename with title llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
using ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/udp_rr-2014-09-19T011359.493548.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_256.json.gz as dump file
Test data is in [../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/udp_rr-2014-09-19T011359.493548.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_256.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
CORES: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
UDP Ports: 1: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
Threads/Port: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
TARGET: 10.113.4.96: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
Server: noServer: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
CLIENTS: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
TCONCURRENCY: 4096: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
CONCURRENCY: 256: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
total TPS: [775902.4419999999]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
vtotal TPS: [775902.4419999999]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
Net_rate: [6.369999999999998]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
avg TPS: [48493.902624999995]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
MIN TPS: [5824.306]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
get_min: [106.75]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
MIN_LATENCY: [106.75]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
RT_LATENCY: [21154.62125]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
P50_LATENCY: [2986.4375]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
P90_LATENCY: [3628.0625]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
P99_LATENCY: [4336.0625]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
MAX_LATENCY: [13398.25]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
USE_TCP: False: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
TITLE: llvmE10k,Intel_S,udp,0,Q_10,P_1No output formatter selected.
Test data is in ../echoServerResults/results/dragonet_e10k_Q10/Q10_run//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_Intel_S_/udp_rr-2014-09-19T011359.493548.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_256.json.gz (use with -i to format).
024,,SRVI_1,SRV_16,C_256: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:16, UDP Ports:1, Threads/Port:16, TARGET:10.113.4.96, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(16, 10, 16, 1, 16, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        16  |         1  |        16  | 10.113.4.  |  noServer  |        16  |      4096  |       256  | [775902.4  | [775902.4  | [6.369999  | [48493.90  | [5824.306  |  [106.75]  |  [106.75]  | [21154.62  | [2986.437  | [3628.062  | [4336.062  | [13398.25  |     False  |llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256  |
