./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 8 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 16 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16 -o ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/ -L ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:03:15:47:Setting up machines

2014-09-22:03:15:52: Start run

2014-09-22:03:15:52: Starting server applications

2014-09-22:03:15:52: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:03:15:52: Starting client applications


2014-09-22:03:15:52: Benchmark running, for threads which are marked for waiting

2014-09-22:03:16:02: Benchmark done (runtime = 9.810423 secs), killing other threads

2014-09-22:03:16:02: Waiting for kill cleanup

2014-09-22:03:16:02: Processing results

2014-09-22:03:16:02: cleaning up server applications


2014-09-22:03:16:02: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
using ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T031547.156100.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_8_C_16.json.gz as dump file
Test data is in [../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T031547.156100.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_8_C_16.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
CORES: 8: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
Threads/Port: 8: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
CLIENTS: 8: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
TCONCURRENCY: 128: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
CONCURRENCY: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
total TPS: [1130162.7170000002]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
vtotal TPS: [1130162.7170000002]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
Net_rate: [9.26]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
avg TPS: [141270.33962500002]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
MIN TPS: [128963.36]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
get_min: [54.625]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
MIN_LATENCY: [54.625]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
RT_LATENCY: [120.5395]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
P50_LATENCY: [115.75]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
P90_LATENCY: [141.25]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
P99_LATENCY: [178.0]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
MAX_LATENCY: [337.625]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
TITLE: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:8, UDP Ports:1, Threads/Port:8, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(8, 10, 8, 1, 8, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARNo output formatter selected.
Test data is in ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T031547.156100.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_8_C_16.json.gz (use with -i to format).
GET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |         8  |         1  |         8  |        SF  |  noServer  |         8  |       128  |        16  | [1130162.  | [1130162.  |    [9.26]  | [141270.3  | [128963.3  |  [54.625]  |  [54.625]  | [120.5395  |  [115.75]  |  [141.25]  |   [178.0]  | [337.625]  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_16  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 8 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 32 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32 -o ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/ -L ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:03:16:08:Setting up machines

2014-09-22:03:16:13: Start run

2014-09-22:03:16:13: Starting server applications

2014-09-22:03:16:13: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:03:16:13: Starting client applications


2014-09-22:03:16:13: Benchmark running, for threads which are marked for waiting

2014-09-22:03:16:23: Benchmark done (runtime = 9.778423 secs), killing other threads

2014-09-22:03:16:23: Waiting for kill cleanup

2014-09-22:03:16:23: Processing results

2014-09-22:03:16:23: cleaning up server applications


2014-09-22:03:16:23: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
using ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T031607.709228.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_8_C_32.json.gz as dump file
Test data is in [../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T031607.709228.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_8_C_32.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
CORES: 8: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
Threads/Port: 8: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
CLIENTS: 8: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
TCONCURRENCY: 256: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
CONCURRENCY: 32: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
total TPS: [1133565.1739999999]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
vtotal TPS: [1133565.1739999999]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
Net_rate: [9.28]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
avg TPS: [141695.64674999999]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
MIN TPS: [130733.516]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
get_min: [48.875]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
MIN_LATENCY: [48.875]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
RT_LATENCY: [233.1075]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
P50_LATENCY: [235.75]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
P90_LATENCY: [248.0]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
P99_LATENCY: [265.625]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
MAX_LATENCY: [461.375]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
TITLE: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:8, UDP Ports:1, Threads/Port:8, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(8, 10, 8, 1, 8, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TNo output formatter selected.
Test data is in ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T031607.709228.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_8_C_32.json.gz (use with -i to format).
ARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |         8  |         1  |         8  |        SF  |  noServer  |         8  |       256  |        32  | [1133565.  | [1133565.  |    [9.28]  | [141695.6  | [130733.5  |  [48.875]  |  [48.875]  | [233.1075  |  [235.75]  |   [248.0]  | [265.625]  | [461.375]  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_32  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 8 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 64 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64 -o ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/ -L ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:03:16:28:Setting up machines

2014-09-22:03:16:33: Start run

2014-09-22:03:16:33: Starting server applications

2014-09-22:03:16:33: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:03:16:33: Starting client applications


2014-09-22:03:16:33: Benchmark running, for threads which are marked for waiting

2014-09-22:03:16:43: Benchmark done (runtime = 9.781348 secs), killing other threads

2014-09-22:03:16:43: Waiting for kill cleanup

2014-09-22:03:16:43: Processing results

2014-09-22:03:16:43: cleaning up server applications


2014-09-22:03:16:43: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
using ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T031628.202223.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_8_C_64.json.gz as dump file
Test data is in [../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T031628.202223.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_8_C_64.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
CORES: 8: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
Threads/Port: 8: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
CLIENTS: 8: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
TCONCURRENCY: 512: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
CONCURRENCY: 64: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
total TPS: [1132963.1400000001]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
vtotal TPS: [1132963.1400000001]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
Net_rate: [9.29]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
avg TPS: [141620.39250000002]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
MIN TPS: [136037.268]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
get_min: [52.125]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
MIN_LATENCY: [52.125]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
RT_LATENCY: [459.08025]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
P50_LATENCY: [456.625]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
P90_LATENCY: [478.875]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
P99_LATENCY: [493.125]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
MAX_LATENCY: [708.0]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
TITLE: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:8, UDP Ports:1, Threads/Port:8, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(8, 10, 8, 1, 8, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |   No output formatter selected.
Test data is in ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T031628.202223.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_8_C_64.json.gz (use with -i to format).
 TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |         8  |         1  |         8  |        SF  |  noServer  |         8  |       512  |        64  | [1132963.  | [1132963.  |    [9.29]  | [141620.3  | [136037.2  |  [52.125]  |  [52.125]  | [459.0802  | [456.625]  | [478.875]  | [493.125]  |   [708.0]  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_8,C_64  |
