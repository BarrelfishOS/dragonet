./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 16 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 16 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16 -o ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/ -L ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:03:23:09:Setting up machines

2014-09-22:03:23:19: Start run

2014-09-22:03:23:19: Starting server applications

2014-09-22:03:23:19: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:03:23:19: Starting client applications


2014-09-22:03:23:19: Benchmark running, for threads which are marked for waiting

2014-09-22:03:23:29: Benchmark done (runtime = 10.010812 secs), killing other threads

2014-09-22:03:23:29: Waiting for kill cleanup

2014-09-22:03:23:29: Processing results

2014-09-22:03:23:29: cleaning up server applications


2014-09-22:03:23:29: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
using ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T032308.903493.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_16.json.gz as dump file
Test data is in [../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T032308.903493.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_16.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
CORES: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
Threads/Port: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
CLIENTS: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
TCONCURRENCY: 256: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
CONCURRENCY: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
total TPS: [942729.203]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
vtotal TPS: [942729.203]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
Net_rate: [7.699999999999998]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
avg TPS: [58920.5751875]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
MIN TPS: [46776.682]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
get_min: [61.625]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
MIN_LATENCY: [61.625]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
RT_LATENCY: [292.6950625]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
P50_LATENCY: [202.6875]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
P90_LATENCY: [534.1875]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
P99_LATENCY: [1545.375]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
MAX_LATENCY: [10080.6875]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
TITLE: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORESNo output formatter selected.
Test data is in ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T032308.903493.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_16.json.gz (use with -i to format).
', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:16, UDP Ports:1, Threads/Port:16, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(16, 10, 16, 1, 16, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        16  |         1  |        16  |        SF  |  noServer  |        16  |       256  |        16  | [942729.2  | [942729.2  | [7.699999  | [58920.57  | [46776.68  |  [61.625]  |  [61.625]  | [292.6950  | [202.6875  | [534.1875  | [1545.375  | [10080.68  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 16 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 32 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32 -o ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/ -L ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:03:23:35:Setting up machines

2014-09-22:03:23:45: Start run

2014-09-22:03:23:45: Starting server applications

2014-09-22:03:23:45: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:03:23:45: Starting client applications


2014-09-22:03:23:45: Benchmark running, for threads which are marked for waiting

2014-09-22:03:23:55: Benchmark done (runtime = 10.046265 secs), killing other threads

2014-09-22:03:23:55: Waiting for kill cleanup

2014-09-22:03:23:55: Processing results

2014-09-22:03:23:55: cleaning up server applications


2014-09-22:03:23:55: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
using ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T032334.713069.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_32.json.gz as dump file
Test data is in [../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T032334.713069.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_32.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
CORES: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
Threads/Port: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
CLIENTS: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
TCONCURRENCY: 512: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
CONCURRENCY: 32: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
total TPS: [435472.12200000003]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
vtotal TPS: [435472.12200000003]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
Net_rate: [3.56]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
avg TPS: [27217.007625000002]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
MIN TPS: [6986.441]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
get_min: [76.1875]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
MIN_LATENCY: [76.1875]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
RT_LATENCY: [1645.0798124999997]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
P50_LATENCY: [1630.0]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
P90_LATENCY: [2639.125]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
P99_LATENCY: [3451.0625]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
MAX_LATENCY: [5940.8125]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
TITLE: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQNo output formatter selected.
Test data is in ../echoServerResults/results/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T032334.713069.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_32.json.gz (use with -i to format).
UEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:16, UDP Ports:1, Threads/Port:16, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(16, 10, 16, 1, 16, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        16  |         1  |        16  |        SF  |  noServer  |        16  |       512  |        32  | [435472.1  | [435472.1  |    [3.56]  | [27217.00  | [6986.441  | [76.1875]  | [76.1875]  | [1645.079  |  [1630.0]  | [2639.125  | [3451.062  | [5940.812  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 16 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 16 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16 -o ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/ -L ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:09:34:35:Setting up machines

2014-09-22:09:34:45: Start run

2014-09-22:09:34:45: Starting server applications

2014-09-22:09:34:45: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:09:34:45: Starting client applications


2014-09-22:09:34:45: Benchmark running, for threads which are marked for waiting

2014-09-22:09:34:55: Benchmark done (runtime = 10.103452 secs), killing other threads

2014-09-22:09:34:55: Waiting for kill cleanup

2014-09-22:09:34:55: Processing results

2014-09-22:09:34:55: cleaning up server applications


2014-09-22:09:34:55: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
using ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T093434.944138.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_16.json.gz as dump file
Test data is in [../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T093434.944138.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_16.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
CORES: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
Threads/Port: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
CLIENTS: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
TCONCURRENCY: 256: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
CONCURRENCY: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
total TPS: [906537.2469999999]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
vtotal TPS: [906537.2469999999]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
Net_rate: [7.43]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
avg TPS: [56658.57793749999]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
MIN TPS: [45255.66]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
get_min: [66.4375]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
MIN_LATENCY: [66.4375]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
RT_LATENCY: [303.86512500000003]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
P50_LATENCY: [202.8125]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
P90_LATENCY: [595.1875]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
P99_LATENCY: [1555.0625]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
MAX_LATENCY: [10937.0]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
TITLE: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: No output formatter selected.
Test data is in ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T093434.944138.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_16.json.gz (use with -i to format).
['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:16, UDP Ports:1, Threads/Port:16, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(16, 10, 16, 1, 16, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        16  |         1  |        16  |        SF  |  noServer  |        16  |       256  |        16  | [906537.2  | [906537.2  |    [7.43]  | [56658.57  | [45255.66  | [66.4375]  | [66.4375]  | [303.8651  | [202.8125  | [595.1875  | [1555.062  | [10937.0]  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_16  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 16 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 32 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32 -o ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/ -L ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:09:35:01:Setting up machines

2014-09-22:09:35:12: Start run

2014-09-22:09:35:12: Starting server applications

2014-09-22:09:35:12: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:09:35:12: Starting client applications


2014-09-22:09:35:12: Benchmark running, for threads which are marked for waiting

2014-09-22:09:35:22: Benchmark done (runtime = 10.096005 secs), killing other threads

2014-09-22:09:35:22: Waiting for kill cleanup

2014-09-22:09:35:22: Processing results

2014-09-22:09:35:22: cleaning up server applications


2014-09-22:09:35:22: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
using ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T093501.167617.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_32.json.gz as dump file
Test data is in [../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T093501.167617.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_32.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
CORES: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
Threads/Port: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
CLIENTS: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
TCONCURRENCY: 512: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
CONCURRENCY: 32: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
total TPS: [913538.141]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
vtotal TPS: [913538.141]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
Net_rate: [7.49]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
avg TPS: [57096.1338125]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
MIN TPS: [51196.135]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
get_min: [74.875]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
MIN_LATENCY: [74.875]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
RT_LATENCY: [580.9114375]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
P50_LATENCY: [504.4375]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
P90_LATENCY: [1006.0]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
P99_LATENCY: [1498.3125]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
MAX_LATENCY: [6283.4375]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
TITLE: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDPNo output formatter selected.
Test data is in ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T093501.167617.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_32.json.gz (use with -i to format).
 Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:16, UDP Ports:1, Threads/Port:16, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(16, 10, 16, 1, 16, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        16  |         1  |        16  |        SF  |  noServer  |        16  |       512  |        32  | [913538.1  | [913538.1  |    [7.49]  | [57096.13  | [51196.13  |  [74.875]  |  [74.875]  | [580.9114  | [504.4375  |  [1006.0]  | [1498.312  | [6283.437  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_32  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 16 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 64 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64 -o ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/ -L ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:09:35:27:Setting up machines

2014-09-22:09:35:38: Start run

2014-09-22:09:35:38: Starting server applications

2014-09-22:09:35:38: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:09:35:38: Starting client applications


2014-09-22:09:35:38: Benchmark running, for threads which are marked for waiting

2014-09-22:09:35:48: Benchmark done (runtime = 10.119314 secs), killing other threads

2014-09-22:09:35:48: Waiting for kill cleanup

2014-09-22:09:35:48: Processing results

2014-09-22:09:35:48: cleaning up server applications


2014-09-22:09:35:48: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
using ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T093527.369168.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_64.json.gz as dump file
Test data is in [../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T093527.369168.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_64.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
CORES: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
Threads/Port: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
CLIENTS: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
TCONCURRENCY: 1024: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
CONCURRENCY: 64: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
total TPS: [1089145.3490000002]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
vtotal TPS: [1089145.3490000002]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
Net_rate: [8.92]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
avg TPS: [68071.58431250001]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
MIN TPS: [47366.458]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
get_min: [110.9375]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
MIN_LATENCY: [110.9375]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
RT_LATENCY: [969.7099374999999]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
P50_LATENCY: [948.5]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
P90_LATENCY: [1276.4375]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
P99_LATENCY: [1660.375]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
MAX_LATENCY: [5519.4375]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
TITLE: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph titNo output formatter selected.
Test data is in ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T093527.369168.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_64.json.gz (use with -i to format).
le: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:16, UDP Ports:1, Threads/Port:16, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(16, 10, 16, 1, 16, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        16  |         1  |        16  |        SF  |  noServer  |        16  |      1024  |        64  | [1089145.  | [1089145.  |    [8.92]  | [68071.58  | [47366.45  | [110.9375  | [110.9375  | [969.7099  |   [948.5]  | [1276.437  | [1660.375  | [5519.437  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_64  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 16 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 128 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128 -o ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/ -L ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:09:35:54:Setting up machines

2014-09-22:09:36:04: Start run

2014-09-22:09:36:04: Starting server applications

2014-09-22:09:36:04: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:09:36:04: Starting client applications


2014-09-22:09:36:04: Benchmark running, for threads which are marked for waiting

2014-09-22:09:36:14: Benchmark done (runtime = 10.143094 secs), killing other threads

2014-09-22:09:36:14: Waiting for kill cleanup

2014-09-22:09:36:14: Processing results

2014-09-22:09:36:14: cleaning up server applications


2014-09-22:09:36:14: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
using ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T093553.684198.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_128.json.gz as dump file
Test data is in [../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T093553.684198.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_128.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
CORES: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
Threads/Port: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
CLIENTS: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
TCONCURRENCY: 2048: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
CONCURRENCY: 128: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
total TPS: [1128699.301]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
vtotal TPS: [1128699.301]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
Net_rate: [9.27]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
avg TPS: [70543.7063125]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
MIN TPS: [56209.683]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
get_min: [109.3125]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
MIN_LATENCY: [109.3125]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
RT_LATENCY: [1864.48975]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
P50_LATENCY: [1854.1875]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
P90_LATENCY: [2209.25]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
P99_LATENCY: [2549.375]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
MAX_LATENCY: [4463.875]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
TITLE: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graphNo output formatter selected.
Test data is in ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T093553.684198.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_128.json.gz (use with -i to format).
 title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:16, UDP Ports:1, Threads/Port:16, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(16, 10, 16, 1, 16, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        16  |         1  |        16  |        SF  |  noServer  |        16  |      2048  |       128  | [1128699.  | [1128699.  |    [9.27]  | [70543.70  | [56209.68  | [109.3125  | [109.3125  | [1864.489  | [1854.187  | [2209.25]  | [2549.375  | [4463.875  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_128  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 16 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 256 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256 -o ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/ -L ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:09:36:20:Setting up machines

2014-09-22:09:36:30: Start run

2014-09-22:09:36:30: Starting server applications

2014-09-22:09:36:30: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:09:36:30: Starting client applications


2014-09-22:09:36:30: Benchmark running, for threads which are marked for waiting

2014-09-22:09:36:40: Benchmark done (runtime = 10.098723 secs), killing other threads

2014-09-22:09:36:40: Waiting for kill cleanup

2014-09-22:09:36:40: Processing results

2014-09-22:09:36:40: cleaning up server applications


2014-09-22:09:36:40: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
using ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T093619.934850.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_256.json.gz as dump file
Test data is in [../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T093619.934850.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_256.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
CORES: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
Threads/Port: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
CLIENTS: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
TCONCURRENCY: 4096: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
CONCURRENCY: 256: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
total TPS: [440773.7199999999]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
vtotal TPS: [440773.7199999999]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
Net_rate: [3.6100000000000003]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
avg TPS: [27548.357499999995]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
MIN TPS: [5095.314]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
get_min: [89.25]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
MIN_LATENCY: [89.25]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
RT_LATENCY: [14026.194000000001]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
P50_LATENCY: [13511.0]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
P90_LATENCY: [16332.9375]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
P99_LATENCY: [18253.4375]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
MAX_LATENCY: [21689.25]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
TITLE: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'No output formatter selected.
Test data is in ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_16/T_16//maxTP_SF_S_/udp_rr-2014-09-22T093619.934850.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_16_C_256.json.gz (use with -i to format).
TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:16, UDP Ports:1, Threads/Port:16, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(16, 10, 16, 1, 16, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        16  |         1  |        16  |        SF  |  noServer  |        16  |      4096  |       256  | [440773.7  | [440773.7  | [3.610000  | [27548.35  | [5095.314  |   [89.25]  |   [89.25]  | [14026.19  | [13511.0]  | [16332.93  | [18253.43  | [21689.25  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_16,C_256  |
