./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 --servercores 18 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 16 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16 -o ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/ -L ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003, 9004, 9004]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:09:40:45:Setting up machines

2014-09-22:09:40:57: Start run

2014-09-22:09:40:57: Starting server applications

2014-09-22:09:40:57: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:09:40:57: Starting client applications


2014-09-22:09:40:57: Benchmark running, for threads which are marked for waiting

2014-09-22:09:41:07: Benchmark done (runtime = 10.114665 secs), killing other threads

2014-09-22:09:41:07: Waiting for kill cleanup

2014-09-22:09:41:07: Processing results

2014-09-22:09:41:07: cleaning up server applications


2014-09-22:09:41:07: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
using ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/udp_rr-2014-09-22T094045.332498.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_18_C_16.json.gz as dump file
Test data is in [../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/udp_rr-2014-09-22T094045.332498.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_18_C_16.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
CORES: 18: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
Threads/Port: 18: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
CLIENTS: 18: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
TCONCURRENCY: 288: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
CONCURRENCY: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
total TPS: [818188.5819999999]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
vtotal TPS: [818188.5819999999]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
Net_rate: [6.73]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
avg TPS: [45454.92122222222]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
MIN TPS: [26455.821]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
get_min: [66.0]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
MIN_LATENCY: [66.0]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
RT_LATENCY: [381.60727777777777]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
P50_LATENCY: [229.94444444444446]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
P90_LATENCY: [861.1111111111111]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
P99_LATENCY: [1907.388888888889]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
MAX_LATENCY: [9307.944444444445]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16
TITLE: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVNo output formatter selected.
Test data is in ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/udp_rr-2014-09-22T094045.332498.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_18_C_16.json.gz (use with -i to format).
I_1,SRV_18,C_16
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:18, UDP Ports:1, Threads/Port:18, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(18, 10, 18, 1, 18, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        18  |         1  |        18  |        SF  |  noServer  |        18  |       288  |        16  | [818188.5  | [818188.5  |    [6.73]  | [45454.92  | [26455.82  |    [66.0]  |    [66.0]  | [381.6072  | [229.9444  | [861.1111  | [1907.388  | [9307.944  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_16  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 --servercores 18 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 32 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32 -o ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/ -L ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003, 9004, 9004]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:09:41:13:Setting up machines

2014-09-22:09:41:24: Start run

2014-09-22:09:41:24: Starting server applications

2014-09-22:09:41:24: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:09:41:24: Starting client applications


2014-09-22:09:41:24: Benchmark running, for threads which are marked for waiting

2014-09-22:09:41:34: Benchmark done (runtime = 10.061483 secs), killing other threads

2014-09-22:09:41:34: Waiting for kill cleanup

2014-09-22:09:41:34: Processing results

2014-09-22:09:41:34: cleaning up server applications


2014-09-22:09:41:34: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
using ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/udp_rr-2014-09-22T094112.668181.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_18_C_32.json.gz as dump file
Test data is in [../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/udp_rr-2014-09-22T094112.668181.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_18_C_32.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
CORES: 18: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
Threads/Port: 18: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
CLIENTS: 18: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
TCONCURRENCY: 576: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
CONCURRENCY: 32: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
total TPS: [873477.092]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
vtotal TPS: [873477.092]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
Net_rate: [7.149999999999999]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
avg TPS: [48526.50511111111]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
MIN TPS: [31855.233]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
get_min: [69.72222222222223]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
MIN_LATENCY: [69.72222222222223]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
RT_LATENCY: [688.082]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
P50_LATENCY: [593.6666666666666]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
P90_LATENCY: [1237.388888888889]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
P99_LATENCY: [1882.0]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
MAX_LATENCY: [5414.5]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32
TITLE: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_1No output formatter selected.
Test data is in ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/udp_rr-2014-09-22T094112.668181.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_18_C_32.json.gz (use with -i to format).
8,C_32
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:18, UDP Ports:1, Threads/Port:18, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(18, 10, 18, 1, 18, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        18  |         1  |        18  |        SF  |  noServer  |        18  |       576  |        32  | [873477.0  | [873477.0  | [7.149999  | [48526.50  | [31855.23  | [69.72222  | [69.72222  | [688.082]  | [593.6666  | [1237.388  |  [1882.0]  |  [5414.5]  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_32  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 --servercores 18 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 64 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64 -o ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/ -L ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003, 9004, 9004]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:09:41:40:Setting up machines

2014-09-22:09:41:52: Start run

2014-09-22:09:41:52: Starting server applications

2014-09-22:09:41:52: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:09:41:52: Starting client applications


2014-09-22:09:41:52: Benchmark running, for threads which are marked for waiting

2014-09-22:09:42:02: Benchmark done (runtime = 10.176747 secs), killing other threads

2014-09-22:09:42:02: Waiting for kill cleanup

2014-09-22:09:42:02: Processing results

2014-09-22:09:42:02: cleaning up server applications


2014-09-22:09:42:02: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
using ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/udp_rr-2014-09-22T094140.037183.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_18_C_64.json.gz as dump file
Test data is in [../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/udp_rr-2014-09-22T094140.037183.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_18_C_64.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
CORES: 18: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
Threads/Port: 18: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
CLIENTS: 18: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
TCONCURRENCY: 1152: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
CONCURRENCY: 64: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
total TPS: [1112098.3879999998]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
vtotal TPS: [1112098.3879999998]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
Net_rate: [9.1]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
avg TPS: [61783.24377777777]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
MIN TPS: [12440.478]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
get_min: [84.72222222222223]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
MIN_LATENCY: [84.72222222222223]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
RT_LATENCY: [1243.220277777778]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
P50_LATENCY: [1191.6666666666667]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
P90_LATENCY: [1752.7222222222222]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
P99_LATENCY: [2422.722222222222]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
MAX_LATENCY: [8683.777777777777]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
TITLE: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64: llvmSFNo output formatter selected.
Test data is in ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/udp_rr-2014-09-22T094140.037183.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_18_C_64.json.gz (use with -i to format).
,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:18, UDP Ports:1, Threads/Port:18, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(18, 10, 18, 1, 18, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        18  |         1  |        18  |        SF  |  noServer  |        18  |      1152  |        64  | [1112098.  | [1112098.  |     [9.1]  | [61783.24  | [12440.47  | [84.72222  | [84.72222  | [1243.220  | [1191.666  | [1752.722  | [2422.722  | [8683.777  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_64  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 --servercores 18 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 128 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128 -o ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/ -L ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003, 9004, 9004]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:09:42:07:Setting up machines

2014-09-22:09:42:19: Start run

2014-09-22:09:42:19: Starting server applications

2014-09-22:09:42:19: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:09:42:19: Starting client applications


2014-09-22:09:42:19: Benchmark running, for threads which are marked for waiting

2014-09-22:09:42:29: Benchmark done (runtime = 10.077867 secs), killing other threads

2014-09-22:09:42:29: Waiting for kill cleanup

2014-09-22:09:42:29: Processing results

2014-09-22:09:42:29: cleaning up server applications


2014-09-22:09:42:29: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
using ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/udp_rr-2014-09-22T094207.559603.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_18_C_128.json.gz as dump file
Test data is in [../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/udp_rr-2014-09-22T094207.559603.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_18_C_128.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
CORES: 18: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
Threads/Port: 18: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
CLIENTS: 18: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
TCONCURRENCY: 2304: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
CONCURRENCY: 128: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
total TPS: [1132981.9730000002]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
vtotal TPS: [1132981.9730000002]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
Net_rate: [9.290000000000001]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
avg TPS: [62943.442944444454]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
MIN TPS: [11854.654]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
get_min: [81.77777777777777]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
MIN_LATENCY: [81.77777777777777]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
RT_LATENCY: [2481.083611111111]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
P50_LATENCY: [2423.8333333333335]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
P90_LATENCY: [3148.722222222222]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
P99_LATENCY: [3946.0555555555557]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
MAX_LATENCY: [11308.055555555555]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
TITLE: llvmSF,SF_S,udpNo output formatter selected.
Test data is in ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/udp_rr-2014-09-22T094207.559603.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_18_C_128.json.gz (use with -i to format).
,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:18, UDP Ports:1, Threads/Port:18, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(18, 10, 18, 1, 18, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        18  |         1  |        18  |        SF  |  noServer  |        18  |      2304  |       128  | [1132981.  | [1132981.  | [9.290000  | [62943.44  | [11854.65  | [81.77777  | [81.77777  | [2481.083  | [2423.833  | [3148.722  | [3946.055  | [11308.05  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_128  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 --servercores 18 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 256 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256 -o ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/ -L ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003, 9004, 9004]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:09:42:35:Setting up machines

2014-09-22:09:42:47: Start run

2014-09-22:09:42:47: Starting server applications

2014-09-22:09:42:47: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:09:42:47: Starting client applications


2014-09-22:09:42:47: Benchmark running, for threads which are marked for waiting

2014-09-22:09:42:57: Benchmark done (runtime = 10.112991 secs), killing other threads

2014-09-22:09:42:57: Waiting for kill cleanup

2014-09-22:09:42:57: Processing results

2014-09-22:09:42:57: cleaning up server applications


2014-09-22:09:42:57: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
using ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/udp_rr-2014-09-22T094234.983143.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_18_C_256.json.gz as dump file
Test data is in [../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/udp_rr-2014-09-22T094234.983143.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_18_C_256.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
CORES: 18: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
Threads/Port: 18: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
CLIENTS: 18: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
TCONCURRENCY: 4608: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
CONCURRENCY: 256: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
total TPS: [1132486.74]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
vtotal TPS: [1132486.74]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
Net_rate: [9.269999999999998]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
avg TPS: [62915.93]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
MIN TPS: [12874.424]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
get_min: [84.27777777777777]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
MIN_LATENCY: [84.27777777777777]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
RT_LATENCY: [4973.291722222222]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
P50_LATENCY: [4633.944444444444]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
P90_LATENCY: [5909.444444444444]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
P99_LATENCY: [7484.111111111111]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
MAX_LATENCY: [15554.166666666666]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
TITLE: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_1No output formatter selected.
Test data is in ../echoServerResults/EchoP1024DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_18/T_18//maxTP_SF_S_/udp_rr-2014-09-22T094234.983143.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_18_C_256.json.gz (use with -i to format).
8,C_256: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:18, UDP Ports:1, Threads/Port:18, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(18, 10, 18, 1, 18, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        18  |         1  |        18  |        SF  |  noServer  |        18  |      4608  |       256  | [1132486.  | [1132486.  | [9.269999  | [62915.93  | [12874.42  | [84.27777  | [84.27777  | [4973.291  | [4633.944  | [5909.444  | [7484.111  | [15554.16  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_18,C_256  |
