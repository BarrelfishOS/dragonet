./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 2 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 16 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16 -o ../echoServerResults/EchoP1024DP/dragonet_SF_Q10_R2/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_SF_S_/ -L ../echoServerResults/EchoP1024DP/dragonet_SF_Q10_R2/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:05:18:36:Setting up machines

2014-09-22:05:18:39: Start run

2014-09-22:05:18:39: Starting server applications

2014-09-22:05:18:39: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:05:18:39: Starting client applications


2014-09-22:05:18:39: Benchmark running, for threads which are marked for waiting

2014-09-22:05:18:48: Benchmark done (runtime = 9.712668 secs), killing other threads

2014-09-22:05:18:48: Waiting for kill cleanup

2014-09-22:05:18:48: Processing results

2014-09-22:05:18:48: cleaning up server applications


2014-09-22:05:18:48: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
using ../echoServerResults/EchoP1024DP/dragonet_SF_Q10_R2/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_SF_S_/udp_rr-2014-09-22T051835.900523.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_16.json.gz as dump file
Test data is in [../echoServerResults/EchoP1024DP/dragonet_SF_Q10_R2/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_SF_S_/udp_rr-2014-09-22T051835.900523.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_16.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
CORES: 2: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
Threads/Port: 2: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
CLIENTS: 4: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
TCONCURRENCY: 64: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
CONCURRENCY: 16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
total TPS: [657944.013]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
vtotal TPS: [657944.013]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
Net_rate: [5.39]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
avg TPS: [164486.00325]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
MIN TPS: [149458.311]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
get_min: [56.75]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
MIN_LATENCY: [56.75]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
RT_LATENCY: [104.3095]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
P50_LATENCY: [103.5]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
P90_LATENCY: [118.0]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
P99_LATENCY: [129.5]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
MAX_LATENCY: [355.75]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
TITLE: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:2, UDP Ports:1, Threads/Port:2, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(2, 10, 2, 1, 2, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATNo output formatter selected.
Test data is in ../echoServerResults/EchoP1024DP/dragonet_SF_Q10_R2/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_SF_S_/udp_rr-2014-09-22T051835.900523.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_16.json.gz (use with -i to format).
EN  |   USE_TCP  |     TITLE  |
|        10  |         2  |         1  |         2  |        SF  |  noServer  |         4  |        64  |        16  | [657944.0  | [657944.0  |    [5.39]  | [164486.0  | [149458.3  |   [56.75]  |   [56.75]  | [104.3095  |   [103.5]  |   [118.0]  |   [129.5]  |  [355.75]  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_16  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 2 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 32 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32 -o ../echoServerResults/EchoP1024DP/dragonet_SF_Q10_R2/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_SF_S_/ -L ../echoServerResults/EchoP1024DP/dragonet_SF_Q10_R2/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:05:18:54:Setting up machines

2014-09-22:05:18:57: Start run

2014-09-22:05:18:57: Starting server applications

2014-09-22:05:18:57: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:05:18:57: Starting client applications


2014-09-22:05:18:57: Benchmark running, for threads which are marked for waiting

2014-09-22:05:19:06: Benchmark done (runtime = 9.712385 secs), killing other threads

2014-09-22:05:19:06: Waiting for kill cleanup

2014-09-22:05:19:06: Processing results

2014-09-22:05:19:06: cleaning up server applications


2014-09-22:05:19:06: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
using ../echoServerResults/EchoP1024DP/dragonet_SF_Q10_R2/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_SF_S_/udp_rr-2014-09-22T051854.042457.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_32.json.gz as dump file
Test data is in [../echoServerResults/EchoP1024DP/dragonet_SF_Q10_R2/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_SF_S_/udp_rr-2014-09-22T051854.042457.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_32.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
CORES: 2: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
Threads/Port: 2: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
CLIENTS: 4: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
TCONCURRENCY: 128: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
CONCURRENCY: 32: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
total TPS: [742139.425]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
vtotal TPS: [742139.425]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
Net_rate: [6.08]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
avg TPS: [185534.85625]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
MIN TPS: [155114.852]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
get_min: [53.0]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
MIN_LATENCY: [53.0]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
RT_LATENCY: [179.7075]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
P50_LATENCY: [178.75]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
P90_LATENCY: [190.75]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
P99_LATENCY: [203.25]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
MAX_LATENCY: [438.0]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
TITLE: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:2, UDP Ports:1, Threads/Port:2, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(2, 10, 2, 1, 2, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LANo output formatter selected.
Test data is in ../echoServerResults/EchoP1024DP/dragonet_SF_Q10_R2/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_SF_S_/udp_rr-2014-09-22T051854.042457.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_32.json.gz (use with -i to format).
TEN  |   USE_TCP  |     TITLE  |
|        10  |         2  |         1  |         2  |        SF  |  noServer  |         4  |       128  |        32  | [742139.4  | [742139.4  |    [6.08]  | [185534.8  | [155114.8  |    [53.0]  |    [53.0]  | [179.7075  |  [178.75]  |  [190.75]  |  [203.25]  |   [438.0]  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_32  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 2 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 1024 --concurrency 64 -t llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64 -o ../echoServerResults/EchoP1024DP/dragonet_SF_Q10_R2/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_SF_S_/ -L ../echoServerResults/EchoP1024DP/dragonet_SF_Q10_R2/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:05:19:12:Setting up machines

2014-09-22:05:19:15: Start run

2014-09-22:05:19:15: Starting server applications

2014-09-22:05:19:15: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:05:19:15: Starting client applications


2014-09-22:05:19:15: Benchmark running, for threads which are marked for waiting

2014-09-22:05:19:25: Benchmark done (runtime = 9.712741 secs), killing other threads

2014-09-22:05:19:25: Waiting for kill cleanup

2014-09-22:05:19:25: Processing results

2014-09-22:05:19:25: cleaning up server applications


2014-09-22:05:19:25: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
using ../echoServerResults/EchoP1024DP/dragonet_SF_Q10_R2/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_SF_S_/udp_rr-2014-09-22T051912.142088.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_64.json.gz as dump file
Test data is in [../echoServerResults/EchoP1024DP/dragonet_SF_Q10_R2/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_SF_S_/udp_rr-2014-09-22T051912.142088.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_64.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
CORES: 2: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
Threads/Port: 2: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
CLIENTS: 4: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
TCONCURRENCY: 256: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
CONCURRENCY: 64: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
total TPS: [735929.888]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
vtotal TPS: [735929.888]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
Net_rate: [6.030000000000001]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
avg TPS: [183982.472]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
MIN TPS: [159394.549]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
get_min: [55.5]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
MIN_LATENCY: [55.5]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
RT_LATENCY: [355.74850000000004]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
P50_LATENCY: [355.5]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
P90_LATENCY: [372.75]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
P99_LATENCY: [384.75]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
MAX_LATENCY: [547.75]: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
TITLE: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64: llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:2, UDP Ports:1, Threads/Port:2, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(2, 10, 2, 1, 2, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  No output formatter selected.
Test data is in ../echoServerResults/EchoP1024DP/dragonet_SF_Q10_R2/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_1024/HWQ_10/0//TP_MAX/P_2/T_2//maxTP_SF_S_/udp_rr-2014-09-22T051912.142088.llvmSF_SF_S_udp_0_Q_10_P_1024__SRVI_1_SRV_2_C_64.json.gz (use with -i to format).
| P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |         2  |         1  |         2  |        SF  |  noServer  |         4  |       256  |        64  | [735929.8  | [735929.8  | [6.030000  | [183982.4  | [159394.5  |    [55.5]  |    [55.5]  | [355.7485  |   [355.5]  |  [372.75]  |  [384.75]  |  [547.75]  |     False  |llvmSF,SF_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_2,C_64  |
