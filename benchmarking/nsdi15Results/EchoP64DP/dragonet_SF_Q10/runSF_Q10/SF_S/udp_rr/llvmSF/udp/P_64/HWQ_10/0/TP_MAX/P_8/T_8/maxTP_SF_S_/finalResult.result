./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 8 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 64 --concurrency 16 -t llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16 -o ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/ -L ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:04:17:14:Setting up machines

2014-09-22:04:17:19: Start run

2014-09-22:04:17:19: Starting server applications

2014-09-22:04:17:19: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:04:17:19: Starting client applications


2014-09-22:04:17:19: Benchmark running, for threads which are marked for waiting

2014-09-22:04:17:29: Benchmark done (runtime = 9.769946 secs), killing other threads

2014-09-22:04:17:29: Waiting for kill cleanup

2014-09-22:04:17:29: Processing results

2014-09-22:04:17:29: cleaning up server applications


2014-09-22:04:17:29: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
using ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T041713.716289.llvmSF_SF_S_udp_0_Q_10_P_64__SRVI_1_SRV_8_C_16.json.gz as dump file
Test data is in [../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T041713.716289.llvmSF_SF_S_udp_0_Q_10_P_64__SRVI_1_SRV_8_C_16.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
CORES: 8: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
Threads/Port: 8: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
CLIENTS: 8: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
TCONCURRENCY: 128: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
CONCURRENCY: 16: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
total TPS: [1509147.59]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
vtotal TPS: [1509147.59]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
Net_rate: [0.77]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
avg TPS: [188643.44875]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
MIN TPS: [154915.928]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
get_min: [44.625]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
MIN_LATENCY: [44.625]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
RT_LATENCY: [91.67649999999999]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
P50_LATENCY: [91.625]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
P90_LATENCY: [100.75]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
P99_LATENCY: [124.25]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
MAX_LATENCY: [278.25]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
TITLE: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:8, UDP Ports:1, Threads/Port:8, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(8, 10, 8, 1, 8, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TNo output formatter selected.
Test data is in ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T041713.716289.llvmSF_SF_S_udp_0_Q_10_P_64__SRVI_1_SRV_8_C_16.json.gz (use with -i to format).
PS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |         8  |         1  |         8  |        SF  |  noServer  |         8  |       128  |        16  | [1509147.  | [1509147.  |    [0.77]  | [188643.4  | [154915.9  |  [44.625]  |  [44.625]  | [91.67649  |  [91.625]  |  [100.75]  |  [124.25]  |  [278.25]  |     False  |llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_16  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 8 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 64 --concurrency 32 -t llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32 -o ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/ -L ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:04:17:34:Setting up machines

2014-09-22:04:17:39: Start run

2014-09-22:04:17:39: Starting server applications

2014-09-22:04:17:39: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:04:17:39: Starting client applications


2014-09-22:04:17:39: Benchmark running, for threads which are marked for waiting

2014-09-22:04:17:49: Benchmark done (runtime = 9.789008 secs), killing other threads

2014-09-22:04:17:49: Waiting for kill cleanup

2014-09-22:04:17:49: Processing results

2014-09-22:04:17:49: cleaning up server applications


2014-09-22:04:17:49: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
using ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T041734.173718.llvmSF_SF_S_udp_0_Q_10_P_64__SRVI_1_SRV_8_C_32.json.gz as dump file
Test data is in [../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T041734.173718.llvmSF_SF_S_udp_0_Q_10_P_64__SRVI_1_SRV_8_C_32.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
CORES: 8: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
Threads/Port: 8: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
CLIENTS: 8: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
TCONCURRENCY: 256: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
CONCURRENCY: 32: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
total TPS: [1539592.6779999998]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
vtotal TPS: [1539592.6779999998]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
Net_rate: [0.77]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
avg TPS: [192449.08474999998]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
MIN TPS: [161647.434]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
get_min: [53.625]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
MIN_LATENCY: [53.625]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
RT_LATENCY: [174.08612499999998]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
P50_LATENCY: [173.375]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
P90_LATENCY: [184.125]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
P99_LATENCY: [197.25]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
MAX_LATENCY: [434.875]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
TITLE: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:8, UDP Ports:1, Threads/Port:8, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(8, 10, 8, 1, 8, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURNo output formatter selected.
Test data is in ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T041734.173718.llvmSF_SF_S_udp_0_Q_10_P_64__SRVI_1_SRV_8_C_32.json.gz (use with -i to format).
RE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |         8  |         1  |         8  |        SF  |  noServer  |         8  |       256  |        32  | [1539592.  | [1539592.  |    [0.77]  | [192449.0  | [161647.4  |  [53.625]  |  [53.625]  | [174.0861  | [173.375]  | [184.125]  |  [197.25]  | [434.875]  |     False  |llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_32  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 8 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 64 --concurrency 64 -t llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64 -o ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/ -L ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:04:17:54:Setting up machines

2014-09-22:04:18:00: Start run

2014-09-22:04:18:00: Starting server applications

2014-09-22:04:18:00: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:04:18:00: Starting client applications


2014-09-22:04:18:00: Benchmark running, for threads which are marked for waiting

2014-09-22:04:18:10: Benchmark done (runtime = 9.785149 secs), killing other threads

2014-09-22:04:18:10: Waiting for kill cleanup

2014-09-22:04:18:10: Processing results

2014-09-22:04:18:10: cleaning up server applications


2014-09-22:04:18:10: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
using ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T041754.627932.llvmSF_SF_S_udp_0_Q_10_P_64__SRVI_1_SRV_8_C_64.json.gz as dump file
Test data is in [../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T041754.627932.llvmSF_SF_S_udp_0_Q_10_P_64__SRVI_1_SRV_8_C_64.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
CORES: 8: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
Threads/Port: 8: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
CLIENTS: 8: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
TCONCURRENCY: 512: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
CONCURRENCY: 64: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
total TPS: [1551592.605]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
vtotal TPS: [1551592.605]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
Net_rate: [0.7899999999999999]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
avg TPS: [193949.075625]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
MIN TPS: [173236.76]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
get_min: [64.875]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
MIN_LATENCY: [64.875]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
RT_LATENCY: [338.807625]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
P50_LATENCY: [337.75]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
P90_LATENCY: [350.5]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
P99_LATENCY: [364.875]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
MAX_LATENCY: [631.75]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
TITLE: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:8, UDP Ports:1, Threads/Port:8, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(8, 10, 8, 1, 8, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  No output formatter selected.
Test data is in ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T041754.627932.llvmSF_SF_S_udp_0_Q_10_P_64__SRVI_1_SRV_8_C_64.json.gz (use with -i to format).
| total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |         8  |         1  |         8  |        SF  |  noServer  |         8  |       512  |        64  | [1551592.  | [1551592.  | [0.789999  | [193949.0  | [173236.7  |  [64.875]  |  [64.875]  | [338.8076  |  [337.75]  |   [350.5]  | [364.875]  |  [631.75]  |     False  |llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_64  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 8 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 64 --concurrency 128 -t llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128 -o ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/ -L ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:04:18:15:Setting up machines

2014-09-22:04:18:20: Start run

2014-09-22:04:18:20: Starting server applications

2014-09-22:04:18:20: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:04:18:20: Starting client applications


2014-09-22:04:18:20: Benchmark running, for threads which are marked for waiting

2014-09-22:04:18:30: Benchmark done (runtime = 9.785095 secs), killing other threads

2014-09-22:04:18:30: Waiting for kill cleanup

2014-09-22:04:18:30: Processing results

2014-09-22:04:18:30: cleaning up server applications


2014-09-22:04:18:30: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
using ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T041815.139796.llvmSF_SF_S_udp_0_Q_10_P_64__SRVI_1_SRV_8_C_128.json.gz as dump file
Test data is in [../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T041815.139796.llvmSF_SF_S_udp_0_Q_10_P_64__SRVI_1_SRV_8_C_128.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
CORES: 8: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
Threads/Port: 8: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
CLIENTS: 8: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
TCONCURRENCY: 1024: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
CONCURRENCY: 128: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
total TPS: [1562187.0380000002]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
vtotal TPS: [1562187.0380000002]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
Net_rate: [0.8099999999999998]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
avg TPS: [195273.37975000002]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
MIN TPS: [172730.141]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
get_min: [77.75]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
MIN_LATENCY: [77.75]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
RT_LATENCY: [668.703125]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
P50_LATENCY: [666.625]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
P90_LATENCY: [684.75]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
P99_LATENCY: [704.875]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
MAX_LATENCY: [848.875]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
TITLE: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:8, UDP Ports:1, Threads/Port:8, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(8, 10, 8, 1, 8, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  | No output formatter selected.
Test data is in ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T041815.139796.llvmSF_SF_S_udp_0_Q_10_P_64__SRVI_1_SRV_8_C_128.json.gz (use with -i to format).
   Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |         8  |         1  |         8  |        SF  |  noServer  |         8  |      1024  |       128  | [1562187.  | [1562187.  | [0.809999  | [195273.3  | [172730.1  |   [77.75]  |   [77.75]  | [668.7031  | [666.625]  |  [684.75]  | [704.875]  | [848.875]  |     False  |llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_128  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H asiago -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 8 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.195 udp_rr --packet 64 --concurrency 256 -t llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256 -o ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/ -L ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_//llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256.log
generating data for machine asiago
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-22:04:18:35:Setting up machines

2014-09-22:04:18:41: Start run

2014-09-22:04:18:41: Starting server applications

2014-09-22:04:18:41: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-22:04:18:41: Starting client applications


2014-09-22:04:18:41: Benchmark running, for threads which are marked for waiting

2014-09-22:04:18:51: Benchmark done (runtime = 9.795080 secs), killing other threads

2014-09-22:04:18:51: Waiting for kill cleanup

2014-09-22:04:18:51: Processing results

2014-09-22:04:18:51: cleaning up server applications


2014-09-22:04:18:51: Done with collecting data


generating filename with title llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
using ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T041835.577764.llvmSF_SF_S_udp_0_Q_10_P_64__SRVI_1_SRV_8_C_256.json.gz as dump file
Test data is in [../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T041835.577764.llvmSF_SF_S_udp_0_Q_10_P_64__SRVI_1_SRV_8_C_256.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
CORES: 8: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
UDP Ports: 1: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
Threads/Port: 8: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
TARGET: SF: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
Server: noServer: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
CLIENTS: 8: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
TCONCURRENCY: 2048: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
CONCURRENCY: 256: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
total TPS: [1556565.156]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
vtotal TPS: [1556565.156]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
Net_rate: [0.7899999999999999]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
avg TPS: [194570.6445]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
MIN TPS: [157904.343]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
get_min: [79.125]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
MIN_LATENCY: [79.125]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
RT_LATENCY: [1342.1474999999998]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
P50_LATENCY: [1313.125]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
P90_LATENCY: [1503.625]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
P99_LATENCY: [1537.125]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
MAX_LATENCY: [1611.125]: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
USE_TCP: False: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
TITLE: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256: llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:8, UDP Ports:1, Threads/Port:8, TARGET:SF, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(8, 10, 8, 1, 8, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    SerNo output formatter selected.
Test data is in ../echoServerResults/EchoP64DP/dragonet_SF_Q10/runSF_Q10//SF_S//udp_rr/llvmSF/udp/P_64/HWQ_10/0//TP_MAX/P_8/T_8//maxTP_SF_S_/udp_rr-2014-09-22T041835.577764.llvmSF_SF_S_udp_0_Q_10_P_64__SRVI_1_SRV_8_C_256.json.gz (use with -i to format).
ver  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |         8  |         1  |         8  |        SF  |  noServer  |         8  |      2048  |       256  | [1556565.  | [1556565.  | [0.789999  | [194570.6  | [157904.3  |  [79.125]  |  [79.125]  | [1342.147  | [1313.125  | [1503.625  | [1537.125  | [1611.125  |     False  |llvmSF,SF_S,udp,0,Q_10,P_64,,SRVI_1,SRV_8,C_256  |
