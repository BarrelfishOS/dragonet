+ local -r -i max_attempts=4
+ shift
+ local -r 'cmd=./netperf-wrapper -d 2 -I 3 -l 50 -c noServer --udp --serverCoreShift 0 -H asiago -C burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C sbrinz1 -C gruyere -C burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C sbrinz1 -C gruyere -C burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C sbrinz1 --servercores 10 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.95 udp_rr --packet 1024 --concurrency 32 -t llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST -o ../echoServerResults/EchoLoadBalacingP1024/Dragonet_E10k_C10///F_20//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/ -L ../echoServerResults/EchoLoadBalacingP1024/Dragonet_E10k_C10///F_20//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_//llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST.log'
+ local -i attempt_num=1
+ echo ./netperf-wrapper -d 2 -I 3 -l 50 -c noServer --udp --serverCoreShift 0 -H asiago -C burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C sbrinz1 -C gruyere -C burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C sbrinz1 -C gruyere -C burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C sbrinz1 --servercores 10 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.95 udp_rr --packet 1024 --concurrency 32 -t llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST -o ../echoServerResults/EchoLoadBalacingP1024/Dragonet_E10k_C10///F_20//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/ -L ../echoServerResults/EchoLoadBalacingP1024/Dragonet_E10k_C10///F_20//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_//llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST.log
./netperf-wrapper -d 2 -I 3 -l 50 -c noServer --udp --serverCoreShift 0 -H asiago -C burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C sbrinz1 -C gruyere -C burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C sbrinz1 -C gruyere -C burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C sbrinz1 --servercores 10 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.95 udp_rr --packet 1024 --concurrency 32 -t llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST -o ../echoServerResults/EchoLoadBalacingP1024/Dragonet_E10k_C10///F_20//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/ -L ../echoServerResults/EchoLoadBalacingP1024/Dragonet_E10k_C10///F_20//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_//llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST.log
+ ./netperf-wrapper -d 2 -I 3 -l 50 -c noServer --udp --serverCoreShift 0 -H asiago -C burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C sbrinz1 -C gruyere -C burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C sbrinz1 -C gruyere -C burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C sbrinz1 --servercores 10 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.95 udp_rr --packet 1024 --concurrency 32 -t llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST -o ../echoServerResults/EchoLoadBalacingP1024/Dragonet_E10k_C10///F_20//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/ -L ../echoServerResults/EchoLoadBalacingP1024/Dragonet_E10k_C10///F_20//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_//llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST.log
Final client list is ['burrata', 'ziger1', 'ziger2', 'sbrinz2', 'appenzeller-e1000', 'sbrinz1', 'gruyere', 'burrata', 'ziger1', 'ziger2', 'sbrinz2', 'appenzeller-e1000', 'sbrinz1', 'gruyere', 'burrata', 'ziger1', 'ziger2', 'sbrinz2', 'appenzeller-e1000', 'sbrinz1']
generating data for machine asiago
generating data for machine burrata
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine sbrinz1
generating data for machine gruyere
generating data for machine burrata
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine sbrinz1
generating data for machine gruyere
generating data for machine burrata
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine sbrinz1
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9002, 9002]
Running experiment for time of 52
Actually running the benchmark to collect data
2014-09-23:12:27:23:Setting up machines

2014-09-23:12:27:37: Start run

2014-09-23:12:27:37: Starting server applications

2014-09-23:12:27:37: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-23:12:27:37: Starting client applications


2014-09-23:12:27:37: Benchmark running, for threads which are marked for waiting

2014-09-23:12:28:32: Benchmark done (runtime = 54.926240 secs), killing other threads

2014-09-23:12:28:32: Waiting for kill cleanup

2014-09-23:12:28:32: Processing results

2014-09-23:12:28:32: cleaning up server applications


2014-09-23:12:28:32: Done with collecting data


2014-09-23:12:28:32:Setting up machines

2014-09-23:12:28:46: Start run

2014-09-23:12:28:46: Starting server applications

2014-09-23:12:28:46: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-23:12:28:46: Starting client applications


2014-09-23:12:28:46: Benchmark running, for threads which are marked for waiting

2014-09-23:12:29:40: Benchmark done (runtime = 54.896993 secs), killing other threads

2014-09-23:12:29:40: Waiting for kill cleanup

2014-09-23:12:29:40: Processing results

2014-09-23:12:29:41: cleaning up server applications


2014-09-23:12:29:41: Done with collecting data


2014-09-23:12:29:41:Setting up machines

2014-09-23:12:29:54: Start run

2014-09-23:12:29:54: Starting server applications

2014-09-23:12:29:54: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-23:12:29:54: Starting client applications


2014-09-23:12:29:54: Benchmark running, for threads which are marked for waiting

2014-09-23:12:30:49: Benchmark done (runtime = 54.921195 secs), killing other threads

2014-09-23:12:30:49: Waiting for kill cleanup

2014-09-23:12:30:49: Processing results

2014-09-23:12:30:49: cleaning up server applications


2014-09-23:12:30:49: Done with collecting data


generating filename with title llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
using ../echoServerResults/EchoLoadBalacingP1024/Dragonet_E10k_C10///F_20//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/udp_rr-2014-09-23T122723.180636.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_10_CLC_20_C_32_BEST.json.gz as dump file
Test data is in [../echoServerResults/EchoLoadBalacingP1024/Dragonet_E10k_C10///F_20//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/No output formatter selected.
Test data is in ../echoServerResults/EchoLoadBalacingP1024/Dragonet_E10k_C10///F_20//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/udp_rr-2014-09-23T122723.180636.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_10_CLC_20_C_32_BEST.json.gz (use with -i to format).
0//TP_MAX/P_10/T_10//maxTP_Intel_S_/udp_rr-2014-09-23T122723.180636.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_10_CLC_20_C_32_BEST.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
CORES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
UDP Ports: 1: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
Threads/Port: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
TARGET: Intel: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
Server: noServer: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
CLIENTS: 20: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
TCONCURRENCY: 640: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
CONCURRENCY: 32: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
total TPS: [1148666.7610000002, 1148574.475, 1148453.234]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
vtotal TPS: [1148666.7610000002, 1148574.475, 1148453.234]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
Net_rate: [9.4, 9.41, 9.4]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
avg TPS: [57433.338050000006, 57428.723750000005, 57422.6617]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
MIN TPS: [56497.455, 55987.461, 55796.782]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
get_min: [122.5, 122.6, 110.9]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
MIN_LATENCY: [122.5, 122.6, 110.9]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
RT_LATENCY: [574.63335, 574.7167999999999, 574.79525]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
P50_LATENCY: [575.5, 575.95, 575.5]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
P90_LATENCY: [611.7, 612.15, 614.2]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
P99_LATENCY: [644.2, 647.0, 648.85]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
MAX_LATENCY: [9737.75, 10874.35, 7674.55]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
USE_TCP: False: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
TITLE: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:10, UDP Ports:1, Threads/Port:10, TARGET:Intel, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CLIENTS']
graph x_axis_other: []
sort order keys: ['CLIENTS', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(20, 10, 10, 1, 10, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        10  |         1  |        10  |     Intel  |  noServer  |        20  |       640  |        32  | [1148666.  | [1148666.  | [9.4, 9.4  | [57433.33  | [56497.45  | [122.5, 1  | [122.5, 1  | [574.6333  | [575.5, 5  | [611.7, 6  | [644.2, 6  | [9737.75,  |     False  |llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,CLC_20,C_32,BEST  |
