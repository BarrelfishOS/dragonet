./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 10 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.96 udp_rr --packet 1024 --concurrency 16 -t llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16 -o ../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/ -L ../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_//llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16.log
generating data for machine burrata
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003, 9004, 9004, 9004, 9004, 9005, 9005, 9005, 9005, 9006, 9006, 9006, 9006, 9007, 9007, 9007, 9007, 9008, 9008, 9008, 9008, 9009, 9009, 9009, 9009]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-19:02:31:52:Setting up machines

2014-09-19:02:32:16: Start run

2014-09-19:02:32:17: Starting server applications

2014-09-19:02:32:17: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-19:02:32:17: Starting client applications


2014-09-19:02:32:17: Benchmark running, for threads which are marked for waiting

2014-09-19:02:32:27: Benchmark done (runtime = 10.863430 secs), killing other threads

2014-09-19:02:32:27: Waiting for kill cleanup

2014-09-19:02:32:27: Processing results

2014-09-19:02:32:27: cleaning up server applications


2014-09-19:02:32:27: Done with collecting data


generating filename with title llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
using ../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/udp_rr-2014-09-19T023152.254553.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_10_C_16.json.gz as dump file
Test data is in [../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/udp_rr-2014-09-19T023152.254553.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_10_C_16.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
CORES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
UDP Ports: 1: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
Threads/Port: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
TARGET: 10.113.4.96: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
Server: noServer: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
CLIENTS: 40: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
TCONCURRENCY: 640: llvmE10No output formatter selected.
Test data is in ../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/udp_rr-2014-09-19T023152.254553.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_10_C_16.json.gz (use with -i to format).
k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
CONCURRENCY: 16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
total TPS: [980289.051]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
vtotal TPS: [980289.051]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
Net_rate: [8.010000000000007]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
avg TPS: [24507.226275]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
MIN TPS: [103.43]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
get_min: [114.025]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
MIN_LATENCY: [114.025]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
RT_LATENCY: [5170.773174999998]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
P50_LATENCY: [5589.45]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
P90_LATENCY: [6102.275]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
P99_LATENCY: [18367.575]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
MAX_LATENCY: [22268.5]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
USE_TCP: False: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
TITLE: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:10, UDP Ports:1, Threads/Port:10, TARGET:10.113.4.96, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(10, 10, 10, 1, 10, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        10  |         1  |        10  | 10.113.4.  |  noServer  |        40  |       640  |        16  | [980289.0  | [980289.0  | [8.010000  | [24507.22  |  [103.43]  | [114.025]  | [114.025]  | [5170.773  | [5589.45]  | [6102.275  | [18367.57  | [22268.5]  |     False  |llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_16  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 10 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.96 udp_rr --packet 1024 --concurrency 32 -t llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32 -o ../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/ -L ../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_//llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32.log
generating data for machine burrata
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003, 9004, 9004, 9004, 9004, 9005, 9005, 9005, 9005, 9006, 9006, 9006, 9006, 9007, 9007, 9007, 9007, 9008, 9008, 9008, 9008, 9009, 9009, 9009, 9009]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-19:02:32:33:Setting up machines

2014-09-19:02:32:57: Start run

2014-09-19:02:32:57: Starting server applications

2014-09-19:02:32:57: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-19:02:32:57: Starting client applications


2014-09-19:02:32:57: Benchmark running, for threads which are marked for waiting

2014-09-19:02:33:08: Benchmark done (runtime = 10.825121 secs), killing other threads

2014-09-19:02:33:08: Waiting for kill cleanup

2014-09-19:02:33:08: Processing results

2014-09-19:02:33:08: cleaning up server applications


2014-09-19:02:33:08: Done with collecting data


generating filename with title llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
using ../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/udp_rr-2014-09-19T023233.027669.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_10_C_32.json.gz as dump file
Test data is in [../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/udp_rr-2014-09-19T023233.027669.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_10_C_32.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
CORES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
UDP Ports: 1: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
Threads/Port: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
TARGET: 10.113.4.96: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
Server: noServer: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
CLIENTS: 40: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
TCONCURRENCY: 1280: llvmE1No output formatter selected.
Test data is in ../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/udp_rr-2014-09-19T023233.027669.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_10_C_32.json.gz (use with -i to format).
0k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
CONCURRENCY: 32: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
total TPS: [1101312.4749999999]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
vtotal TPS: [1101312.4749999999]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
Net_rate: [8.989999999999998]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
avg TPS: [27532.811874999996]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
MIN TPS: [977.146]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
get_min: [194.6]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
MIN_LATENCY: [194.6]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
RT_LATENCY: [2726.418875]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
P50_LATENCY: [1083.225]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
P90_LATENCY: [1221.9]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
P99_LATENCY: [30567.825]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
MAX_LATENCY: [38830.5]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
USE_TCP: False: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
TITLE: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:10, UDP Ports:1, Threads/Port:10, TARGET:10.113.4.96, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(10, 10, 10, 1, 10, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        10  |         1  |        10  | 10.113.4.  |  noServer  |        40  |      1280  |        32  | [1101312.  | [1101312.  | [8.989999  | [27532.81  | [977.146]  |   [194.6]  |   [194.6]  | [2726.418  | [1083.225  |  [1221.9]  | [30567.82  | [38830.5]  |     False  |llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_32  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 10 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.96 udp_rr --packet 1024 --concurrency 64 -t llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64 -o ../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/ -L ../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_//llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64.log
generating data for machine burrata
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003, 9004, 9004, 9004, 9004, 9005, 9005, 9005, 9005, 9006, 9006, 9006, 9006, 9007, 9007, 9007, 9007, 9008, 9008, 9008, 9008, 9009, 9009, 9009, 9009]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-19:02:33:14:Setting up machines

2014-09-19:02:33:38: Start run

2014-09-19:02:33:38: Starting server applications

2014-09-19:02:33:38: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-19:02:33:38: Starting client applications


2014-09-19:02:33:38: Benchmark running, for threads which are marked for waiting

2014-09-19:02:33:49: Benchmark done (runtime = 10.793666 secs), killing other threads

2014-09-19:02:33:49: Waiting for kill cleanup

2014-09-19:02:33:49: Processing results

2014-09-19:02:33:49: cleaning up server applications


2014-09-19:02:33:49: Done with collecting data


generating filename with title llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
using ../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/udp_rr-2014-09-19T023313.789830.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_10_C_64.json.gz as dump file
Test data is in [../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/udp_rr-2014-09-19T023313.789830.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_10_C_64.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
CORES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
UDP Ports: 1: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
Threads/Port: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
TARGET: 10.113.4.96: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
Server: noServer: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
CLIENTS: 40: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
TCONCURRENCY: 2560: llvmE1No output formatter selected.
Test data is in ../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/udp_rr-2014-09-19T023313.789830.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_10_C_64.json.gz (use with -i to format).
0k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
CONCURRENCY: 64: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
total TPS: [1175359.571]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
vtotal TPS: [1175359.571]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
Net_rate: [9.650000000000002]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
avg TPS: [29383.989275]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
MIN TPS: [1902.933]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
get_min: [364.725]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
MIN_LATENCY: [364.725]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
RT_LATENCY: [3382.4009749999996]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
P50_LATENCY: [1988.55]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
P90_LATENCY: [2279.4]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
P99_LATENCY: [40938.375]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
MAX_LATENCY: [53333.575]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
USE_TCP: False: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
TITLE: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:10, UDP Ports:1, Threads/Port:10, TARGET:10.113.4.96, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(10, 10, 10, 1, 10, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        10  |         1  |        10  | 10.113.4.  |  noServer  |        40  |      2560  |        64  | [1175359.  | [1175359.  | [9.650000  | [29383.98  | [1902.933  | [364.725]  | [364.725]  | [3382.400  | [1988.55]  |  [2279.4]  | [40938.37  | [53333.57  |     False  |llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_64  |
./netperf-wrapper -d 2 -I 1 -l 5 -c noServer --udp --serverCoreShift 0 -H burrata -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 -C ziger1 -C ziger2 -C sbrinz2 -C appenzeller-e1000 --servercores 10 --serverInstances 1 --hwqueues 10 --clientcores 1 -T 10.113.4.96 udp_rr --packet 1024 --concurrency 128 -t llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128 -o ../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/ -L ../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_//llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128.log
generating data for machine burrata
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
generating data for machine ziger1
generating data for machine ziger2
generating data for machine sbrinz2
generating data for machine appenzeller-e1000
port_list_for_clients dst: [888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888]
port_list_for_clients src: [9000, 9000, 9000, 9000, 9001, 9001, 9001, 9001, 9002, 9002, 9002, 9002, 9003, 9003, 9003, 9003, 9004, 9004, 9004, 9004, 9005, 9005, 9005, 9005, 9006, 9006, 9006, 9006, 9007, 9007, 9007, 9007, 9008, 9008, 9008, 9008, 9009, 9009, 9009, 9009]
Running experiment for time of 7
Actually running the benchmark to collect data
2014-09-19:02:33:55:Setting up machines

2014-09-19:02:34:19: Start run

2014-09-19:02:34:19: Starting server applications

2014-09-19:02:34:19: Making sure that servers are up

Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
Running is_ready_cmd on machine [server-0] 
Server has no isready cmd
2014-09-19:02:34:19: Starting client applications


2014-09-19:02:34:19: Benchmark running, for threads which are marked for waiting

2014-09-19:02:34:30: Benchmark done (runtime = 10.853800 secs), killing other threads

2014-09-19:02:34:30: Waiting for kill cleanup

2014-09-19:02:34:30: Processing results

2014-09-19:02:34:30: cleaning up server applications


2014-09-19:02:34:30: Done with collecting data


generating filename with title llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
using ../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/udp_rr-2014-09-19T023354.580037.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_10_C_128.json.gz as dump file
Test data is in [../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/udp_rr-2014-09-19T023354.580037.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_10_C_128.json.gz] (use with -i to format).

Data available for processing, analyzing it
HWQUEUES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
CORES: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
UDP Ports: 1: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
Threads/Port: 10: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
TARGET: 10.113.4.96: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
Server: noServer: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
CLIENTS: 40: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
TCONCURRENCY: 51No output formatter selected.
Test data is in ../echoServerResults/loadBalacing/Dragonet_Intel_Q10/Q10_run//F_10//F_20//F_30//F_40//Intel_S//udp_rr/llvmE10k/udp/P_1024/HWQ_10/0//TP_MAX/P_10/T_10//maxTP_Intel_S_/udp_rr-2014-09-19T023354.580037.llvmE10k_Intel_S_udp_0_Q_10_P_1024__SRVI_1_SRV_10_C_128.json.gz (use with -i to format).
20: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
CONCURRENCY: 128: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
total TPS: [1161925.413]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
vtotal TPS: [1161925.413]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
Net_rate: [9.510000000000003]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
avg TPS: [29048.135325]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
MIN TPS: [2078.319]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
get_min: [580.45]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
MIN_LATENCY: [580.45]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
RT_LATENCY: [7097.337650000001]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
P50_LATENCY: [3975.35]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
P90_LATENCY: [5347.95]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
P99_LATENCY: [101571.85]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
MAX_LATENCY: [111493.7]: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
USE_TCP: False: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
TITLE: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128: llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128
meta titles: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: ['HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
graph title: HWQUEUES:10, CORES:10, UDP Ports:1, Threads/Port:10, TARGET:10.113.4.96, Server:noServer, USE_TCP:False
graph x_axis: []
graph x_axis_main: ['CORES']
graph x_axis_other: []
sort order keys: ['CORES', 'HWQUEUES', 'CORES', 'UDP Ports', 'Threads/Port', 'TARGET', 'Server', 'USE_TCP']
[(10, 10, 10, 1, 10, 0)]
[0]
|  HWQUEUES  |     CORES  | UDP Ports  | Threads/P  |    TARGET  |    Server  |   CLIENTS  | TCONCURRE  | CONCURREN  | total TPS  | vtotal TP  |  Net_rate  |   avg TPS  |   MIN TPS  |   get_min  | MIN_LATEN  | RT_LATENC  | P50_LATEN  | P90_LATEN  | P99_LATEN  | MAX_LATEN  |   USE_TCP  |     TITLE  |
|        10  |        10  |         1  |        10  | 10.113.4.  |  noServer  |        40  |      5120  |       128  | [1161925.  | [1161925.  | [9.510000  | [29048.13  | [2078.319  |  [580.45]  |  [580.45]  | [7097.337  | [3975.35]  | [5347.95]  | [101571.8  | [111493.7  |     False  |llvmE10k,Intel_S,udp,0,Q_10,P_1024,,SRVI_1,SRV_10,C_128  |
