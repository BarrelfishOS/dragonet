

What questions will be asked to the NIC hardware model?
What type of answers are expected from them?

What are the modules involved in this system?
How do they interact?


Why does a simple list of features in hardware will not be enough?
Why you need something as heavyweight as type-system and functional
programming language?

Example scenario:

Mixed Server workload:
Why would anyone use mixed server workloads?
Machines are having more and more cores which can't be used by single server
(or single server can't scale to all of them), in such scenarios it will be
reasonable to assume that single machine will be running multiple servers.
The number of NIC's connected to these machines will be limited compared
to number of cores, and hence multiple applications will have to share the
NIC hardware between them.

Example mixed Server workload:
    - Key Value store (memcached) which is latency sensitive
    - Webserver  (Throughput sensitive, large number of incoming requests)
    - Storage server/client (small number of persistent connections)
    - NFS server

What I want is a mixture of following
    - Large number of incoming connections (same listen port)
    - Large number of outgoing connections (large number of ports) maybe a web-crawler??
    - Lot of incoming data
    - Lot of outgoing data (video streaming)





Qus: Why not use the Virtualization and give one virtual machine to each server?
Ans: This solution might work, as each server gets different MAC and IP address,
it is much easier for NIC to do hardware filtering.  This is actually a quite
big plus point for virtualization.
TODO: Find a weakness in virtualization approach.




Example:
A machine with lot of cores (eg: 32) and cores are divided into CPU packages
and hence NUMA domains.   User wants to
run a
 - Web-server (large number of incoming connections on same port, need high throughput)
 - Key-value store (large number of incoming connections on same port, need low latency)
 - Database server (small number of incoming connections, large outgoing data, latency sensitive)
 - Backup Server (small number of incoming connections, large incoming data, throughput bound)

The machine has one Intel 10G card which has
 - 128 send(TX)/receive(RX) queues
 - 128 exact matching 5 tuple filters
 - FIXME: need more assumptions about hardware filtering and their limitations


Question: How to allocate networking resources between these applications?
How to organize their network stack?

Webserver:
Threads running on different cores (maybe those cores are on different NUMA nodes)
Load balancing at connection level
Batching to improve throughput

Software filtering or hardware filtering?

Most likely hardware filtering will not be suitable in this case because of
too many short lived connections.  It does not make sense to insert a filter
(which will take some time) when connection is not going to last very long.
We might be able to insert a single listen filter, which takes all traffic to
load balancer, which then redirects it to proper core.

If not hardware filtering, then how would you load balance?


It is a tread-off between how expensive it is to insert hardware filter
to how long this connection will remain active?


DNS server:
short lived connections(single packet request/response), UDP,

In case of DNS server, where request resides in one packet, we might be able
to use hardware load-balancing based on hashing


